{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (21.0.1)\n",
      "Requirement already satisfied: smart_open in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (4.2.0)\n",
      "Requirement already satisfied: minecart in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (0.3.0)\n",
      "Requirement already satisfied: pdfminer3k in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from minecart) (1.3.4)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from minecart) (1.15.0)\n",
      "Requirement already satisfied: ply in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pdfminer3k->minecart) (3.11)\n",
      "Requirement already satisfied: textract-trp in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (0.1.3)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install --upgrade pip\n",
    "pip install smart_open minecart\n",
    "pip install textract-trp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import re\n",
    "import os\n",
    "import trp\n",
    "import boto3\n",
    "import minecart\n",
    "import json\n",
    "import logging \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from smart_open import open\n",
    "from sagemaker.session import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate s3 bucket and corresponding data folder\n",
    "bucket = \"ran-s3-systemic-risk\"\n",
    "data_folder =\"Input/X-17A-5-Subsets/\"\n",
    "\n",
    "# script to perform OCR (using Textract) for X-17A-5 subsets\n",
    "out_folder = 'Output/X-17A-5-BS/'\n",
    "\n",
    "# Amazon Textract client and Sagemaker session\n",
    "textract = boto3.client('textract')\n",
    "s3 = boto3.client('s3')\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Asynchronous Textract Script (requesting Job)\n",
    "**Content modified from Amazon AWS Textract repository (refer to [URL](https://github.com/aws-samples/amazon-textract-code-samples/blob/master/python/12-pdf-text.py) below)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startJob(s3BucketName:str, objectName:str) -> str:\n",
    "    \"\"\"\n",
    "    Starts a Textract job on AWS server \n",
    "    \"\"\"\n",
    "    response = None\n",
    "    client = boto3.client('textract')\n",
    "    \n",
    "    # issue response to AWS to start Textract job for table analysis \n",
    "    response = client.start_document_analysis(\n",
    "        DocumentLocation={\n",
    "            'S3Object': {\n",
    "                'Bucket': s3BucketName,\n",
    "                'Name': objectName\n",
    "            }\n",
    "        },\n",
    "        FeatureTypes=['FORMS', 'TABLES']    # selecting forms and tables from the OCR\n",
    "    )\n",
    "    \n",
    "    # return response job ID for service\n",
    "    return response[\"JobId\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isJobComplete(jobId:str) -> str:\n",
    "    \"\"\"\n",
    "    Tracks the completion status of the Textract job when qued\n",
    "    \"\"\"\n",
    "    time.sleep(1)\n",
    "    client = boto3.client('textract')\n",
    "    response = client.get_document_analysis(JobId=jobId)\n",
    "    status = response[\"JobStatus\"]\n",
    "    print(\"Job status: {}\".format(status))\n",
    "    \n",
    "    # check current status of AWS job (ask server every 5 seconds for data)\n",
    "    while(status == \"IN_PROGRESS\"):\n",
    "        time.sleep(5)                   # lag before reporting status\n",
    "        response = client.get_document_analysis(JobId=jobId)\n",
    "        status = response[\"JobStatus\"]\n",
    "        print(\"Job status: {}\".format(status))\n",
    "    \n",
    "    return status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getJobResults(jobId:str) -> list:\n",
    "    \"\"\"\n",
    "    Returns the contents of the Textract job, after completion status met\n",
    "    \"\"\"\n",
    "    pages = []          # initialize list object to track pages\n",
    "\n",
    "    client = boto3.client('textract')\n",
    "    response = client.get_document_analysis(JobId=jobId)\n",
    "    \n",
    "    pages.append(response)\n",
    "    print(\"Resultset page recieved: {}\".format(len(pages)))\n",
    "    \n",
    "    nextToken = None\n",
    "    if('NextToken' in response):\n",
    "        nextToken = response['NextToken']\n",
    "    \n",
    "    # iterate through the pages and append to response figure\n",
    "    while(nextToken):\n",
    "        response = client.get_document_analysis(JobId=jobId, NextToken=nextToken)\n",
    "        pages.append(response)\n",
    "        print(\"Resultset page recieved: {}\".format(len(pages)))\n",
    "        nextToken = None\n",
    "        if('NextToken' in response):\n",
    "            nextToken = response['NextToken']\n",
    "\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runJob(bucket:str, key:str):\n",
    "    \"\"\"\n",
    "    Function designed to call an AWS Textract \n",
    "    \"\"\"\n",
    "    # S3 storage for files on AWS site   \n",
    "    jobId = startJob(bucket, key)   # intialize Textract job \n",
    "    print(\"Started job with id: {}\".format(jobId))\n",
    "\n",
    "    # if job is complete from AWS return response object \n",
    "    if(isJobComplete(jobId)):\n",
    "        response = getJobResults(jobId)\n",
    "        \n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Extraction Scripts (Key-Value Pairs)\n",
    "**The content was modified from AWS to extract key-value pairs in form documents from Block objects that are stored in a map. (refer to [URL](https://docs.aws.amazon.com/textract/latest/dg/examples-extract-kvp.html))**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kv_relationship(key_map, value_map, block_map):\n",
    "    \"\"\"\n",
    "    Retreaving the Key-Value relationship from FORM \n",
    "    \"\"\"\n",
    "    key_value_map = {}\n",
    "    \n",
    "    # unpack the key_map to retrieve the block id and key names\n",
    "    for block_id, key_block in key_map.items():\n",
    "        # retrieve value block given job id\n",
    "        value_block = find_value_block(key_block, value_map)\n",
    "\n",
    "        # get text value from key and value blocks\n",
    "        key = get_text(key_block, block_map)\n",
    "        val = get_text(value_block, block_map)\n",
    "        \n",
    "        # map the key and value pairs\n",
    "        key_value_map[key] = val\n",
    "        \n",
    "    return key_value_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_value_block(key_block, value_map):\n",
    "    \"\"\"\n",
    "    Retrieving value block from AWS textract job \n",
    "    \"\"\"\n",
    "    for relationship in key_block['Relationships']:\n",
    "        if relationship['Type'] == 'VALUE':\n",
    "            for value_id in relationship['Ids']:\n",
    "                value_block = value_map[value_id]\n",
    "    return value_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(result, blocks_map):\n",
    "    \"\"\"\n",
    "    Retrieving text values from given work\n",
    "    \"\"\"\n",
    "    text = ''\n",
    "    if 'Relationships' in result:\n",
    "        for relationship in result['Relationships']:\n",
    "            if relationship['Type'] == 'CHILD':\n",
    "                for child_id in relationship['Ids']:\n",
    "                    word = blocks_map[child_id]\n",
    "                    \n",
    "                    # if word then we append to space\n",
    "                    if word['BlockType'] == 'WORD':\n",
    "                        text += word['Text'] + ' '\n",
    "                    if word['BlockType'] == 'SELECTION_ELEMENT':\n",
    "                        if word['SelectionStatus'] == 'SELECTED':\n",
    "                            text += 'X '    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR Wrapper Functions\n",
    "**The scripts perform an OCR job from AWS Textract, and returning well formated data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trp2df(table:trp.Table) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function designed to convert a trp table into a dataframe\n",
    "    :param table: a trp table object parsed from a pdf  \n",
    "    :return: a DataFrame object housing a textracted trp table\n",
    "    \n",
    "    Complexity -> O(n^2) approx.\n",
    "    \"\"\"\n",
    "    N = len(table.rows)               # number of rows in table\n",
    "    M = len(table.rows[0].cells)      # number of columns in table\n",
    "    arr = [0]*N\n",
    "    \n",
    "    # iterate through each row within the provided table\n",
    "    for row in np.arange(N):\n",
    "        \n",
    "        # strip the text from the cell references to construct (N X M) matrix\n",
    "        arr[row] = [table.rows[row].cells[col].text.strip() for col in np.arange(M)]\n",
    "        \n",
    "    return pd.DataFrame(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTable(response:list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function to transform AWS Textract object to a dataframe, by searching for tables\n",
    "    :param response: AWS Textract response object\n",
    "    \"\"\"\n",
    "    # in the event multiple tables detected on one page (concat them)\n",
    "    catDF = []\n",
    "    \n",
    "    # format the Textract response type \n",
    "    doc = trp.Document(response)\n",
    "    \n",
    "    # iterate through document pages\n",
    "    for page in doc.pages:\n",
    "        \n",
    "        # itterate through page tables\n",
    "        for table in page.tables: \n",
    "            \n",
    "            # convert trp-table into dataframe object\n",
    "            df = trp2df(table)\n",
    "            \n",
    "            # remove columns that are completly empty\n",
    "            empty_cols = [col for col in df.columns if (df[col] == '').all()]\n",
    "            df = df.drop(empty_cols, axis=1)\n",
    "  \n",
    "            # number of columns in dataframe\n",
    "            n = df.columns.size\n",
    "            \n",
    "            # reset the column names (avoid the column names)\n",
    "            df.columns = np.arange(n)\n",
    "            \n",
    "            ##############################################################\n",
    "            #                           NOTES\n",
    "            #          a good dataframe should have 2-3 columns\n",
    "            #      anything more or less is a reading error we ignore\n",
    "            ##############################################################\n",
    "            \n",
    "            # if the dataframe has more than 3 columns then we most likley have an issue in parsing\n",
    "            if n > 3:\n",
    "                return None\n",
    "            \n",
    "            elif n > 1:\n",
    "                \n",
    "                ##############################\n",
    "                # Balance Sheet Assummptions\n",
    "                ##############################\n",
    "                \n",
    "                lineIndex = df.columns[0]\n",
    "\n",
    "                # check for the word \"cash\" in a string at the begining, ignoring case sensitivity (asset check)\n",
    "                assetCheck = df[lineIndex].str.contains('^Cash', regex=True, flags=re.IGNORECASE)\n",
    "\n",
    "                # check for the word \"Liabilities\" in a string at the end, ignoring case sensitivity (liability check)\n",
    "                debtCheck1 = df[lineIndex].str.contains('Liabilities$|^Liabilities', regex=True, flags=re.IGNORECASE)\n",
    "                debtCheck2 = df[lineIndex].str.contains('Liability$|^Liability', regex=True, flags=re.IGNORECASE)\n",
    "                \n",
    "                # check for the presence of $ sign, we assume the balance sheet items should have presence of $ sign\n",
    "                # used to handle table of contents error caused from prior reads\n",
    "                dollarCheck = df[df.columns[1]].str.contains('\\$[^\\]]+', regex=True, flags=re.IGNORECASE)\n",
    "                \n",
    "                ##############################\n",
    "                # Balance Sheet Determination\n",
    "                ##############################\n",
    "                \n",
    "                # check if the key words have been found \n",
    "                check1 = df[assetCheck | debtCheck1 | debtCheck2].empty      # check for terms, and $ presence\n",
    "                check2 = df[dollarCheck == True].empty                       # check for presence of '$' sign  \n",
    "                check3 = df[debtCheck1 == True].empty                        # debt check for Liabilities\n",
    "                check4 = df[debtCheck2 == True].empty                        # debt check for Liability \n",
    "                \n",
    "                # if either asset term or liability term is found, with a $ sign we append the dataframe\n",
    "                if not check1 and not check2:\n",
    "                    catDF.append(df)      # we append since sometimes asset and liablility tables are seperated \n",
    "\n",
    "                    if not check3 or not check4:\n",
    "                        # if liability table was found on the first iteration we simply concat data frames and return \n",
    "                        return pd.concat(catDF)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readForm(response:list) -> dict:\n",
    "    \"\"\"\n",
    "    Function to transform AWS Textract object to a dictionary, by searching for key value pairs\n",
    "    :param response: AWS Textract response object\n",
    "    \"\"\"\n",
    "    # format the Textract response type \n",
    "    doc = trp.Document(response)\n",
    "    \n",
    "    # initializing \n",
    "    key_map = {}\n",
    "    value_map = {}\n",
    "    block_map = {}\n",
    "\n",
    "    # iterate through document pages\n",
    "    for page in doc.pages:\n",
    "\n",
    "        # itterate through page tables\n",
    "        for block in page.blocks: \n",
    "\n",
    "            # store the block id in map to retrive information later\n",
    "            block_id = block['Id']\n",
    "            block_map[block_id] = block\n",
    "\n",
    "            # if Key-value set has been seen \n",
    "            if block['BlockType'] == \"KEY_VALUE_SET\":\n",
    "\n",
    "                # if KEY is labeled as entity type then we found Key, else we found VALUE\n",
    "                if 'KEY' in block['EntityTypes']:\n",
    "                    key_map[block_id] = block\n",
    "                else:\n",
    "                    value_map[block_id] = block\n",
    "\n",
    "    return get_kv_relationship(key_map, value_map, block_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Balance Sheet information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textractParse(path:str, index:int, csvDirectory:np.ndarray, bucket:str = \"ran-s3-systemic-risk\", \n",
    "                  out_folder:str = 'Output/X-17A-5-BS/') -> dict:\n",
    "    \"\"\"\n",
    "    Function runs a Textract job and saves Balance Sheet information to .csv file in s3 folder \n",
    "    \"\"\"\n",
    "    errors = ''\n",
    "    \n",
    "    # track the presence of json file storing information on forms\n",
    "    if os.path.exists('X17A5-forms.json'):\n",
    "        with open('X17A5-forms.json', 'r') as f: forms = json.loads(f.read())\n",
    "    else:\n",
    "        forms = {}\n",
    "    \n",
    "    # baseFile name to name export .csv file e.g. 782124-2002.csv\n",
    "    baseFile = '-'.join(path.split('/')[-1].split('-')[:2])\n",
    "    fileName = baseFile + '.csv'\n",
    "    print('\\nPerforming OCR for {}'.format(baseFile))\n",
    "\n",
    "    # if file is not found in directory we continue the iteration process\n",
    "    if (out_folder + fileName not in csvDirectory) or (baseFile not in forms):\n",
    "\n",
    "        # temporary data frame object for balance sheet information\n",
    "        res = runJob(\"ran-s3-systemic-risk\", path)\n",
    "        \n",
    "        # if Textract job did not fail we continue extraction\n",
    "        if res[0]['JobStatus'] != 'FAILED':\n",
    "            # retrieve structured data pulls from OCR\n",
    "            forms[baseFile] = readForm(res)\n",
    "            tempDF = readTable(res)\n",
    "            \n",
    "            print(tempDF)\n",
    "            \n",
    "            # checks for type of return, if none then we log an error\n",
    "            if type(tempDF) == pd.DataFrame:\n",
    "                \n",
    "                # writing data frame to .csv file\n",
    "                tempDF.to_csv(fileName, index=False)\n",
    "\n",
    "                # save contents to AWS S3 bucket\n",
    "                with open(fileName, 'rb') as data:\n",
    "                    s3.put_object(Bucket=bucket, Key=out_folder + fileName, Body=data)\n",
    "\n",
    "                # remove local file after it has been created\n",
    "                os.remove(fileName)\n",
    "                \n",
    "                print('-----------------------------------------------------')\n",
    "                print('Saved {} file to s3 bucket'.format(baseFile + '.csv'))\n",
    "            else:\n",
    "                errors = 'No Balance Sheet found, or parsing error'\n",
    "        else:\n",
    "            errors = 'Could not parse, JOB FAILEDs'\n",
    "    else:\n",
    "        print('{} has been downloaded'.format(fileName))\n",
    "        \n",
    "    # storing key-value line items\n",
    "    with open('X17A5-forms.json', 'w') as f: json.dump(forms, f)\n",
    "        \n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing OCR for 782124-2019\n",
      "Started job with id: a4f030c774c8f79d8a2bb9845c64f6347d6986096a3bca481fc079071998928c\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: SUCCEEDED\n",
      "Resultset page recieved: 1\n",
      "Resultset page recieved: 2\n",
      "Resultset page recieved: 3\n",
      "Resultset page recieved: 4\n",
      "Resultset page recieved: 5\n",
      "Resultset page recieved: 6\n",
      "Resultset page recieved: 7\n",
      "Resultset page recieved: 8\n",
      "Resultset page recieved: 9\n",
      "Resultset page recieved: 10\n",
      "                                                    0          1\n",
      "0                                              Assets           \n",
      "1                                                Cash    $ 8,835\n",
      "2   Securities purchased under resale agreements (...    179,143\n",
      "3                                 Securities borrowed     77,344\n",
      "4   Securities received as collateral, at fair val...      2,625\n",
      "5                          Receivables from customers     29,248\n",
      "6   Receivables from brokers, dealers, clearing or...     15,734\n",
      "7   Financial instruments owned, at fair value (in...    143,468\n",
      "8                                            Goodwill      1,356\n",
      "9           Other assets (included $56 at fair value)      2,512\n",
      "10                                     Total assets(a  $ 460,265\n",
      "11                                        Liabilities           \n",
      "12  Short-term borrowings (included $2,863 at fair...   $ 55,335\n",
      "13  Securities sold under repurchase agreements (i...    218,539\n",
      "14                                  Securities loaned      7,426\n",
      "15  Obligation to return securities received as co...      2,945\n",
      "16                              Payables to customers     86,062\n",
      "17  Payables to brokers, dealers, clearing organiz...      8,311\n",
      "18  Financial instruments sold, not yet purchased,...     33,270\n",
      "19             Other liabilities and accrüed expenses      3,377\n",
      "20  Beneficial interests issued by consolidated va...         26\n",
      "21                      Long-term debt, at fair value     11,784\n",
      "22                                 Total liabilities³    427,075\n",
      "23        Commitments and contingencies (see Note 15)           \n",
      "24                            Subordinated borrowings     24,000\n",
      "25                                    Member's equity           \n",
      "26                                  Member's interest      6,167\n",
      "27                                  Retained earnings     3,023-\n",
      "28                              Total member's equity      9,190\n",
      "29              Total liabilities and member's equity  $ 460,265\n",
      "-----------------------------------------------------\n",
      "Saved 782124-2019.csv file to s3 bucket\n"
     ]
    }
   ],
   "source": [
    "# csv Directory to store balance sheet information \n",
    "csvs = np.array(session.list_s3_files(bucket, out_folder))\n",
    "\n",
    "# discover all of the pdfs that you want to parse\n",
    "paths = np.array(session.list_s3_files(bucket, data_folder))[1:]\n",
    "\n",
    "errorDict = {}\n",
    "\n",
    "# iterate through X-17A-5 subsets stored in s3 \n",
    "for i, key in enumerate(['Input/X-17A-5-Subsets/782124-2019-subset.pdf']):     \n",
    "    val = textractParse(key, i, csvs)\n",
    "    \n",
    "    if val != '':\n",
    "        errorDict[key] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing unique list of asset items and liability line items\n",
    "with open('textractErrors.json', 'w') as f: json.dump(errorDict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
