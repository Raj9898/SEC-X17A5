{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sagemaker.session import Session\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.feature_extraction.text import HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator LinearSVC from version 0.22.1 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator GridSearchCV from version 0.22.1 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "assetMDL = load('Outs/asset_svc_mdl_v1.joblib')\n",
    "liableMDL = load('Outs/liability_svc_mdl_v1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in asset and liability dataframes\n",
    "assetDF = pd.read_csv('unstructAsset.csv')\n",
    "liableDF = pd.read_csv('unstructLiable.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# journal of physics A, Journal Stat. Physics\n",
    "def structured_data(unstructured_df:pd.DataFrame, cluster_df:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Constructs a structured dataset from an unstructured column set\n",
    "    \n",
    "    :param: unstructured_df (type pandas.DataFrame)\n",
    "        unstuructured pandas dataframe with loose column construction \n",
    "    :param: cluster_df (type pandas.DataFrame)\n",
    "        a pandas dataframe of clustered labels and corresponding line items\n",
    "    :param: (type numpy array)\n",
    "        all corresponding cluster labels cirresponding with 'cluster_df' parameter\n",
    "        \n",
    "    :return: (type pandas DataFrame)\n",
    "    \"\"\"\n",
    "    \n",
    "    structured_df = pd.DataFrame()\n",
    "    label_names = np.unique(cluster_df.Labels.values)\n",
    "    remap = {}\n",
    "    \n",
    "    # assume that the there exists columns 'CIK' and 'Year' for unstructured data\n",
    "    structured_df = unstructured_df[['CIK', 'Name', 'Year']]\n",
    "    \n",
    "    for label in label_names:\n",
    "        data = cluster_df[cluster_df['Labels'] == label]['LineItems']     # filter by corresponding cluster\n",
    "        \n",
    "        # we first select all predicted columns, then sum across rows for only numeric figures\n",
    "        selection = unstructured_df[data.values]\n",
    "        \n",
    "        sumV = selection.sum(axis=1, numeric_only=True)\n",
    "        \n",
    "        # we then select rows from the original unstructured dataframe with only np.nan and convert sumV index to np.nan\n",
    "        # handle for Missing (NaN) and blank terms (0.0)\n",
    "        sumV[selection.isnull().all(axis=1)] = np.nan\n",
    "        \n",
    "        # assign dictionary to have labels and matching vector\n",
    "        remap[label] = sumV\n",
    "\n",
    "    structured_df = structured_df.assign(**remap)   \n",
    "    return structured_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def company_pdf(df:pd.DataFrame, mdl):\n",
    "    \"\"\"\n",
    "    Return a dataframe for a company showcasing its column names, the predicted class and the original values\n",
    "    \"\"\"\n",
    "    \n",
    "    # split values for company dataframe according to columns and values\n",
    "    colNames = df.index\n",
    "    colValues = df.values\n",
    "    \n",
    "    # predicting the column groups\n",
    "    predNames = mdl.predict(HashingVectorizer(n_features=1000).fit_transform(colNames))\n",
    "    \n",
    "    retDF = pd.DataFrame({'Original Lineitems': colNames, 'Predicted Lineitems': predNames, 'Line values': colValues})\n",
    "    \n",
    "    return retDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Classificaiton model to predict label names for each line item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_predictions = pd.DataFrame([assetDF.columns[3:], \n",
    "                                  assetMDL.predict(HashingVectorizer(n_features=1000).fit_transform(assetDF.columns[3:]))], \n",
    "                                 index=['LineItems', 'Labels']).T\n",
    "\n",
    "liable_predictions = pd.DataFrame([liableDF.columns[3:], \n",
    "                                   liableMDL.predict(HashingVectorizer(n_features=1000).fit_transform(liableDF.columns[3:]))], \n",
    "                                  index=['LineItems', 'Labels']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured Asset Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the strucutred data set for asset terms\n",
    "tempdf = structured_data(assetDF, asset_predictions)\n",
    "tempdf.to_csv('structAsset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured Liability Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the strucutred data set \n",
    "tempdf = structured_data(liableDF, liable_predictions)\n",
    "tempdf.to_csv('structLiable.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# company_pdf(liableDF[(liableDF.CIK == 91154) & (liableDF.Year == 2002)].iloc[0].iloc[3:].dropna(), liableMDL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
