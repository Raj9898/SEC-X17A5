{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (21.0.1)\n",
      "Requirement already satisfied: smart_open in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (4.1.2)\n",
      "Requirement already satisfied: minecart in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (0.3.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from minecart) (1.15.0)\n",
      "Requirement already satisfied: pdfminer3k in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from minecart) (1.3.4)\n",
      "Requirement already satisfied: ply in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pdfminer3k->minecart) (3.11)\n",
      "Requirement already satisfied: textract-trp in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (0.1.3)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install --upgrade pip\n",
    "pip install smart_open minecart\n",
    "pip install textract-trp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import re\n",
    "import os\n",
    "import trp\n",
    "import boto3\n",
    "import minecart\n",
    "import json\n",
    "import logging \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from smart_open import open\n",
    "from sagemaker.session import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate s3 bucket and corresponding data folder\n",
    "bucket = \"ran-s3-systemic-risk\"\n",
    "data_folder =\"Input/X-17A-5-Subsets/\"\n",
    "\n",
    "# script to perform OCR (using Textract) for X-17A-5 subsets\n",
    "out_folder = 'Output/X-17A-5-BS/'\n",
    "\n",
    "# Amazon Textract client and Sagemaker session\n",
    "textract = boto3.client('textract')\n",
    "s3 = boto3.client('s3')\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = np.array(session.list_s3_files(bucket, out_folder))[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We begin by first stripping away NaN terms in the first column and then mapping all the NaN terms to an empty string**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All .csv files are cleaned of NaN terms\n"
     ]
    }
   ],
   "source": [
    "for csv in paths:\n",
    "    fileName = csv.split('/')[-1]\n",
    "\n",
    "    # work on combining columns that are issued seperately\n",
    "    s3.download_file(bucket, csv, 'temp.pdf')\n",
    "    df = pd.read_csv('temp.pdf')\n",
    "\n",
    "    # first begin by filtering out the NaN rows present in the first column\n",
    "    filterDF = df[np.isin(df[df.columns[0]], df[df.columns[0]].dropna())]\n",
    "    filterDF = filterDF.fillna('')\n",
    "\n",
    "    # writing data frame to .csv file\n",
    "    filterDF.to_csv(fileName, index=False)\n",
    "\n",
    "    # save contents to AWS S3 bucket\n",
    "    with open(fileName, 'rb') as data:\n",
    "        s3.put_object(Bucket=bucket, Key=out_folder + fileName, Body=data)\n",
    "\n",
    "    # remove local file after it has been created\n",
    "    os.remove(fileName)\n",
    "\n",
    "    # remove local file after it has been created\n",
    "    os.remove('temp.pdf')\n",
    "    \n",
    "print('All .csv files are cleaned of NaN terms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table column merging\n",
    "**For tables with three columns we merge the last two columns into a once unique column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def singular_merge(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function passes a special dataframe, and reduces its dimensions accordingly\n",
    "    - Example releases include but are note limited to 1224385-2016, 72267-2003\n",
    "    ----\n",
    "    e.g.\n",
    "    \n",
    "    Converts a wide dataframe, balance sheet into a smaller rectangular form\n",
    "                  0                                                 1                 2\n",
    "            ====================================================================================\n",
    "        0   Assets                      \n",
    "        1   Cash and cash equivalents                       | $ 606,278      |     \n",
    "        2   Cash and securities segregated pursuant         | 273,083        | \n",
    "        3   Collateralized short-term financing agreements: | NaN            | $ 1,345\n",
    "    \n",
    "    \n",
    "    Rectangular form of the the dataframe ->\n",
    "                   0                                                 1          \n",
    "            =====================================================================\n",
    "        0   Assets                      \n",
    "        1   Cash and cash equivalents                       | $ 606,278        \n",
    "        2   Cash and securities segregated pursuant         | 273,083        \n",
    "        3   Collateralized short-term financing agreements: | $ 1,345            \n",
    "    \"\"\"\n",
    "    cleanDF = pd.DataFrame()\n",
    "    \n",
    "    df = df.fillna('')    # fill all NaN values with empty string\n",
    "    \n",
    "    # create first column of new dataframe that corresponds with first column in prior data\n",
    "    cleanDF['0'] = df[df.columns[0]]\n",
    "\n",
    "    # we assume that the second and third columns are filled with figures\n",
    "    cleanDF['1'] = df[df.columns[1]] + df[df.columns[2]]\n",
    "    \n",
    "    return cleanDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We merged 1224385-2016.csv\n"
     ]
    }
   ],
   "source": [
    "for csv in paths:\n",
    "    fileName = csv.split('/')[-1]\n",
    "    \n",
    "    # work on combining columns that are issued seperately\n",
    "    s3.download_file(bucket, csv, 'temp.pdf')\n",
    "    df = pd.read_csv('temp.pdf')\n",
    "    \n",
    "    # if columns greater than 2, we have a weird data table\n",
    "    if df.columns.size > 2:\n",
    "        \n",
    "        # two events could occur at this point (either total splits, or year splits)\n",
    "        arr = df[df.columns[2]].values\n",
    "        \n",
    "        # check the scope of the second column \n",
    "        n = arr.size\n",
    "        k = arr.tolist().count(np.nan)\n",
    "        \n",
    "        # if more than half the arr size is np.nan we assume this is a \"fake column\"\n",
    "        # we merge these columns since there are many blank rows, otherwise we assume year split \n",
    "        if k >= int(n/2):\n",
    "            tempDF = singular_merge(df)\n",
    "        else:\n",
    "            tempDF = df[df.columns[:2]]\n",
    "\n",
    "        # writing data frame to .csv file\n",
    "        tempDF.to_csv(fileName, index=False)\n",
    "\n",
    "        # save contents to AWS S3 bucket\n",
    "        with open(fileName, 'rb') as data:\n",
    "            s3.put_object(Bucket=bucket, Key=out_folder + fileName, Body=data)\n",
    "        \n",
    "        print('We merged {}'.format(fileName))\n",
    "        # remove local file after it has been created\n",
    "        os.remove(fileName)\n",
    "\n",
    "    # remove local file after it has been created\n",
    "    os.remove('temp.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Row Split\n",
    "**Since many of the existing tables run the risk of overlapping rows we work to split these rows to appropriate values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_split(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function designed to split conjoined rows from Balance sheet dataframes\n",
    "    - Example releases include but are note limited to 42352-2015, 58056-2009, 58056-2013\n",
    "    \n",
    "    NOTE: Our objective isn't to achieve a perfect split, but rather create labels easy enough for our predictive \n",
    "    model to identify and accurately predict. This is not a perfect method and we make assumptions as to the data \n",
    "    \"\"\"\n",
    "    \n",
    "    def find_splits(val) -> bool:\n",
    "        \"\"\"\n",
    "        Compute a boolean measure to assess whether a row is conjoined or not \n",
    "        \"\"\"\n",
    "        try:\n",
    "            # split the data figures for each balance sheet figure\n",
    "            x = val.split(' ')\n",
    "            \n",
    "            # remove the $ sign if present in the list (this helps avoid false pasitives) \n",
    "            try:\n",
    "                x.remove('$')\n",
    "            except ValueError:\n",
    "                # if no $ found we just ignore\n",
    "                pass\n",
    "            \n",
    "            # if length of read list exceeds 1 then we know there exists a multi-row bunch\n",
    "            if len(x) > 1:\n",
    "                return True\n",
    "            else: return False\n",
    "        except AttributeError: return False\n",
    "    \n",
    "    # select all the rows that match our description, where a space exists \n",
    "    selections = df[df[df.columns[1]].apply(lambda x: find_splits(x))]\n",
    "    idxs = selections.index\n",
    "\n",
    "    # initialize the reporting dataframe\n",
    "    temp_df = df\n",
    "\n",
    "    for i in idxs:\n",
    "\n",
    "        # slice dataframe according to the idx selection (we search for all periods were a break occurs)\n",
    "        top = temp_df.loc[:i-1]\n",
    "        bottom = temp_df.loc[i+1:]\n",
    "\n",
    "        # divide the identified term from the selection piece\n",
    "        # e.g. \"$ 9,112,943 13,151,663\" -> [\"$\", \"9,112,943\", \"13,151,663\"] \n",
    "        values = temp_df[temp_df.columns[1]].loc[i].split(' ')\n",
    "\n",
    "        # remove the $ sign if present in the list, otherwise pass \n",
    "        try: values.remove('$')\n",
    "        except ValueError: pass\n",
    "        \n",
    "        lineName = temp_df[temp_df.columns[0]].loc[i]\n",
    "        split = int(len(lineName) * .66)   # index where to cut the string (we assign a 66% cut-off)\n",
    "\n",
    "        # forming dataframe from dictionary, we then re-map columns and index values (these are new rows)\n",
    "        # zip restricts bounds to left most split (so always two rows are returned)\n",
    "        # e.g. dict(zip(['A', 'B'], [1, 2, 3, 4])) -> {'A': 1, 'B': 2}\n",
    "        mid = pd.DataFrame.from_dict(dict(zip([lineName[:split], lineName[split:]], values)), \n",
    "                                     orient='index').reset_index()\n",
    "        mid.columns = ['0', '1']\n",
    "        mid.index = [0, 0]\n",
    "\n",
    "        # reassign the value of df2 to update across each iteration\n",
    "        temp_df = pd.concat([top, mid, bottom])\n",
    "        \n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for csv in paths:\n",
    "    fileName = csv.split('/')[-1]\n",
    "    \n",
    "    # work on combining columns that are issued seperately\n",
    "    s3.download_file(bucket, csv, 'temp.pdf')\n",
    "    df = pd.read_csv('temp.pdf')\n",
    "    \n",
    "    tempDF = row_split(df)\n",
    "    \n",
    "    # if difference is found then \n",
    "    if tempDf.shape != df.shape:\n",
    "        print(\"Fixed the rows for {}\".format(fileName))\n",
    "        \n",
    "        # writing data frame to .csv file\n",
    "        tempDF.to_csv(fileName, index=False)\n",
    "\n",
    "        # save contents to AWS S3 bucket\n",
    "        with open(fileName, 'rb') as data:\n",
    "            s3.put_object(Bucket=bucket, Key=out_folder + fileName, Body=data)\n",
    "\n",
    "        # remove local file after it has been created\n",
    "        os.remove(fileName)\n",
    "\n",
    "    # remove local file after it has been created\n",
    "    os.remove('temp.pdf')\n",
    "    \n",
    "print('\\nWe fixed all conjoined tables in sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Totals Removal\n",
    "**Some tables have rows that record the intermediate totals for a particular line item category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# issues with unpacking total values from tables 42352-2005\n",
    "s3.download_file(bucket, 'Output/X-17A-5-BS/42352-2005.csv', 'temp.pdf')\n",
    "\n",
    "df = pd.read_csv('temp.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cash and cash equivalents</td>\n",
       "      <td>$ 665,532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cash and securities segregated in compliance w...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and other regulations</td>\n",
       "      <td>33,665,205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Receivables from brokers, dealers and clearing...</td>\n",
       "      <td>8,974,752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Receivables from customers and counterparties</td>\n",
       "      <td>12,342,912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Securities borrowed</td>\n",
       "      <td>193,784,018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Securities purchased under agreements to resell</td>\n",
       "      <td>30,376,416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Financial instruments owned, at fair value</td>\n",
       "      <td>50,257,864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Financial instruments owned and pledged as col...</td>\n",
       "      <td>15,194,916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Total financial instruments owned, at fair value</td>\n",
       "      <td>65,452,780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Other assets</td>\n",
       "      <td>3,329,362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Total assets</td>\n",
       "      <td>$ 348,590,977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Liabilities and Partners' Capital</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Short-term borrowings</td>\n",
       "      <td>$ 44,011,767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Payables to brokers, dealers and clearing orga...</td>\n",
       "      <td>7,844,614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Payables to customers and counterparties</td>\n",
       "      <td>86,042,195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Securities loaned</td>\n",
       "      <td>100,701,593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Securities sold under agreements to repurchase</td>\n",
       "      <td>47,313,677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Financial instruments sold, but not yet purcha...</td>\n",
       "      <td>40,404,806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Other liabilities and accrued expenses</td>\n",
       "      <td>4,542,417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Long-term borrowings</td>\n",
       "      <td>1,519,157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Commitments, contingencies and guarantees</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Subordinated borrowings</td>\n",
       "      <td>12,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Partners' capital</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Partners' capital</td>\n",
       "      <td>4,207,332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Accumulated other comprehensive income</td>\n",
       "      <td>3,419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Total partners' capital</td>\n",
       "      <td>4,210,751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Total liabilities and partners' capital</td>\n",
       "      <td>$ 348,590,977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0              1\n",
       "0                           Cash and cash equivalents      $ 665,532\n",
       "1   Cash and securities segregated in compliance w...            NaN\n",
       "2                               and other regulations     33,665,205\n",
       "3   Receivables from brokers, dealers and clearing...      8,974,752\n",
       "4       Receivables from customers and counterparties     12,342,912\n",
       "5                                 Securities borrowed    193,784,018\n",
       "6     Securities purchased under agreements to resell     30,376,416\n",
       "7          Financial instruments owned, at fair value     50,257,864\n",
       "8   Financial instruments owned and pledged as col...     15,194,916\n",
       "9    Total financial instruments owned, at fair value     65,452,780\n",
       "10                                       Other assets      3,329,362\n",
       "11                                       Total assets  $ 348,590,977\n",
       "12                  Liabilities and Partners' Capital            NaN\n",
       "13                              Short-term borrowings   $ 44,011,767\n",
       "14  Payables to brokers, dealers and clearing orga...      7,844,614\n",
       "15           Payables to customers and counterparties     86,042,195\n",
       "16                                  Securities loaned    100,701,593\n",
       "17     Securities sold under agreements to repurchase     47,313,677\n",
       "18  Financial instruments sold, but not yet purcha...     40,404,806\n",
       "19             Other liabilities and accrued expenses      4,542,417\n",
       "20                               Long-term borrowings      1,519,157\n",
       "21          Commitments, contingencies and guarantees            NaN\n",
       "22                            Subordinated borrowings     12,000,000\n",
       "23                                  Partners' capital            NaN\n",
       "24                                  Partners' capital      4,207,332\n",
       "25             Accumulated other comprehensive income          3,419\n",
       "26                            Total partners' capital      4,210,751\n",
       "27            Total liabilities and partners' capital  $ 348,590,977"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check for the word \"cash\" in a string at the begining, ignoring case sensitivity (asset check)\n",
    "# df[df.columns[0]].str.contains('^Total', regex=True, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df[df.columns[1]].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.count(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
