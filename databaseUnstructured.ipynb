{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sagemaker.session import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate s3 bucket and corresponding data folder\n",
    "bucket = \"ran-s3-systemic-risk\"\n",
    "data_folder =\"Output/X-17A-5-BS/\"\n",
    "\n",
    "# Amazon Textract client and Sagemaker session\n",
    "textract = boto3.client('textract')\n",
    "s3 = boto3.client('s3')\n",
    "session = Session()\n",
    "\n",
    "# discover all of the pdfs that you want to parse\n",
    "paths = np.array(session.list_s3_files(bucket, data_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanNumeric(value) -> float:\n",
    "    \"\"\"\n",
    "    This function converts a string to a numeric quantity, handles weird string format\n",
    "    :param: value, string value with hidden numeric quanity  \n",
    "    :return: floating point values\n",
    "    \n",
    "    Complexity -> O(n)\n",
    "    \n",
    "    e.g.\n",
    "        In[0]: $ 19,225     ->   Out[0]: 19255\n",
    "        In[0]: $ 19,225.76  ->   Out[0]: 19255.76\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    assert type(value) is str or int or np.ndarray, 'Value must be of type string, integer, float or numpy array'\n",
    "    \n",
    "    # checks to see what type of value is being provided\n",
    "    operator = type(value)\n",
    "    \n",
    "    def num_strip(number):\n",
    "        \"\"\"\n",
    "        Nested function for extracting numerical quantities\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # some accounting formats take () to be negative numbers\n",
    "            if number[0] == '(':\n",
    "                number = '-' + number\n",
    "\n",
    "            # perform regex operation scanning for only numeric quantities/identifiers\n",
    "            cleanValue = re.sub(\"[^0-9|.|-]\", \"\", number)\n",
    "\n",
    "            # last check against poor lagging formats e.g. \".\" or \"-\" to return nan or floating-point number\n",
    "            try: \n",
    "                return float(cleanValue)\n",
    "            except ValueError: \n",
    "                return np.nan\n",
    "            \n",
    "        except (TypeError, IndexError):\n",
    "            return np.nan\n",
    "    \n",
    "    # if provided a string, perform regex operation \n",
    "    if (operator is str) and (len(value) > 0):\n",
    "        return num_strip(value)\n",
    "    \n",
    "    # if operator is integer then simply return the value, no need to modify \n",
    "    elif (operator is int):\n",
    "        return value\n",
    "    \n",
    "    # if operator is numpy array then we perform a extraction per element in array\n",
    "    elif (operator is np.ndarray):\n",
    "        vFunc = np.vectorize(num_strip)      # vectorize function to apply to numpy array\n",
    "        cleanValue = vFunc(value)            # apply vector function\n",
    "        return cleanValue\n",
    "    \n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('assetLines.txt', 'r') as f: assetSide = json.loads(f.read())\n",
    "with open('liabilityLines.txt', 'r') as f: liableSide = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assetDict = dict([(i, np.nan) for i in assetSide])\n",
    "liableDict = dict([(i, np.nan) for i in liableSide])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unstructured_data(filepaths, lineDictionary, lineItems) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Forms unstructured data frame from .csv file(s) located in s3 bucket\n",
    "    \n",
    "    :param: filepaths\n",
    "        filepaths from s3 that store .csv file(s) (/Output/BalanceSheet/)\n",
    "    :paran: lineDictionary\n",
    "        dictionary of total unstructured line items and corresponding values\n",
    "    :paran: lineItems\n",
    "        list of line items (asset/liabilites) that will be searched for\n",
    "        \n",
    "    :return: tuple\n",
    "        Returns a tuple, itters is a list of dataframes representing line items, error is a dictionary\n",
    "        tracking all error terms that exist due to univariate dataframes \n",
    "    \"\"\"\n",
    "    \n",
    "    # intialize list to store dataframes and errors\n",
    "    itters = [0] * filepaths.size\n",
    "    \n",
    "    # iterate through files from s3 \n",
    "    for i, file in enumerate(filepaths):\n",
    "        \n",
    "        # create temporary dictionary copy for storage of values\n",
    "        tempDict = lineDictionary.copy()\n",
    "        \n",
    "        # creating two rows to track the CIK and year information released\n",
    "        cik, year = file.split('/')[-1].split('-')\n",
    "        \n",
    "        tempDict['CIK'] = cik                 # CIK number for firm \n",
    "        tempDict['Year'] = year[:4]           # Year for firm filing  \n",
    "        \n",
    "        # retrieving downloaded files from s3 bucket\n",
    "        s3.download_file(bucket, file, 'temp.pdf')\n",
    "        df = pd.read_csv('temp.pdf')\n",
    "        \n",
    "        # clean dataframe should be of size greater than 1\n",
    "        if len(df.columns) > 1:\n",
    "            \n",
    "            # extract line items from each dataframe (balance sheet)\n",
    "            lines = df[df.columns[0]]\n",
    "            \n",
    "            # filter dataframes according line items, and extract numerical values from dataframe \n",
    "            filterDF = df[np.isin(lines, lineItems)]\n",
    "            filterDF = filterDF.set_index(filterDF.columns[0])             # set line items as index\n",
    "            filterDF = filterDF.apply(lambda x: cleanNumeric(x.values))    # convert string values to numerical figures\n",
    "            \n",
    "            # iterate through items from (asset or liability items)\n",
    "            for item in filterDF.index:\n",
    "                lineVal = filterDF.loc[item]                 # line item e.g. Cash $72,343 $71,231\n",
    "                \n",
    "                # check to see scope of line value, checking if multi-rows present (Type DataFrame)\n",
    "                # in the event we have repeating 'item' lines (e.g. 2 Prepaid expense categories) we sum columns  \n",
    "                if type(lineVal) is not pd.Series:\n",
    "                    lineVal = lineVal.sum()\n",
    "                \n",
    "                value = lineVal.iloc[0]                      # first column value e.g. 72343, either singular or sum \n",
    "                \n",
    "                # value of line items for the adjacent column (current year)\n",
    "                # some dataframes have multiple year releases (e.g. FY 2020, FY 2019)\n",
    "                if ~np.isnan(value):\n",
    "                    tempDict[item] = value\n",
    "                    \n",
    "                else:\n",
    "                    try:\n",
    "                        # if the first column is blank we assume the second column is filled with totals\n",
    "                        value = lineVal.iloc[1]\n",
    "                        \n",
    "                        # if second column value is not-nan we attach those values\n",
    "                        if ~np.isnan(value):\n",
    "                            tempDict[item] = value\n",
    "                    \n",
    "                    # if no second column exists, we ignore and pass\n",
    "                    except IndexError: pass\n",
    "            \n",
    "            # convert the dictionary values to dataframe for database construction \n",
    "            row = pd.DataFrame.from_dict(tempDict, orient='index')\n",
    "            \n",
    "            # append dataframe set to array transposing \n",
    "            itters[i] = row.T\n",
    "            \n",
    "        else:\n",
    "            print('{} - encountered issue reading PDF'.format(file))\n",
    "        \n",
    "        # remove local file after it has been created\n",
    "        os.remove('temp.pdf')\n",
    "    \n",
    "    return pd.concat(itters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfBuild(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    # re-order the CIK and Year columns to appear as the first two columns\n",
    "    remap = df.columns[~np.isin(df.columns, ['CIK', 'Year'])]\n",
    "    df = df[np.insert(remap, [0, 0], ['CIK', 'Year'])]\n",
    "\n",
    "    # filter out columns with NaN values, return only values\n",
    "    filterNaN = df.isnull().all()\n",
    "    cleanCols = filterNaN[filterNaN == False].index\n",
    "\n",
    "    # clean dataframe for unstructured asset terms\n",
    "    return df[cleanCols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unstructured data table from all .csv files \n",
    "assetItters = unstructured_data(paths[1:], assetDict, assetSide)\n",
    "assetDF = dfBuild(assetItters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assetDF.to_csv('unstructAsset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unstructured data table from all .csv files \n",
    "liableItters = unstructured_data(paths[1:], liableDict, liableSide)\n",
    "liableDF = dfBuild(liableItters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "liableDF.to_csv('unstructLiable.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
