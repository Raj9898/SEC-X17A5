{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting smart_open\n",
      "  Downloading smart_open-5.1.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 2.9 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting minecart\n",
      "  Downloading minecart-0.3.0-py3-none-any.whl (23 kB)\n",
      "Collecting textract-trp\n",
      "  Downloading textract_trp-0.1.3-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from minecart) (1.15.0)\n",
      "Collecting pdfminer3k\n",
      "  Downloading pdfminer3k-1.3.4-py3-none-any.whl (100 kB)\n",
      "\u001b[K     |████████████████████████████████| 100 kB 6.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: ply in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pdfminer3k->minecart) (3.11)\n",
      "Installing collected packages: pdfminer3k, textract-trp, smart-open, minecart\n",
      "Successfully installed minecart-0.3.0 pdfminer3k-1.3.4 smart-open-5.1.0 textract-trp-0.1.3\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Run on first instance to install required libraries\n",
    "%pip install smart_open minecart textract-trp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import re\n",
    "import os\n",
    "import trp\n",
    "import boto3\n",
    "import minecart\n",
    "import json\n",
    "import logging \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from smart_open import open\n",
    "from sagemaker.session import Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Asynchronous Textract Script (requesting Job)\n",
    "**Content modified from Amazon AWS Textract repository (refer to [URL](https://github.com/aws-samples/amazon-textract-code-samples/blob/master/python/12-pdf-text.py) below)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startJob(s3BucketName:str, objectName:str) -> str:\n",
    "    \"\"\"\n",
    "    Starts a Textract job on AWS server \n",
    "    \"\"\"\n",
    "    # initialize return and client object\n",
    "    response = None                         \n",
    "    client = boto3.client('textract')\n",
    "    \n",
    "    # issue response to AWS to start Textract job for table analysis \n",
    "    response = client.start_document_analysis(\n",
    "        DocumentLocation={\n",
    "            'S3Object': {\n",
    "                'Bucket': s3BucketName,     # location of data to be read from s3 bucket \n",
    "                'Name': objectName}},       # file name to be read from Textract  \n",
    "        FeatureTypes=['FORMS', 'TABLES']    # selecting FORMS (key-values) and TABLES from the OCR\n",
    "    )\n",
    "    \n",
    "    # return response job ID for service\n",
    "    return response[\"JobId\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isJobComplete(jobId:str) -> str:\n",
    "    \"\"\"\n",
    "    Tracks the completion status of the Textract job when queued\n",
    "    \"\"\"\n",
    "    # allow for interal sleep timer (efficiency)\n",
    "    time.sleep(1)                               \n",
    "    \n",
    "    client = boto3.client('textract')\n",
    "    response = client.get_document_analysis(JobId=jobId)\n",
    "    \n",
    "    # job-status of the response object \n",
    "    status = response[\"JobStatus\"]                        \n",
    "    print(\"Job status: {}\".format(status))\n",
    "    \n",
    "    # if job still running check current status every 5 seconds\n",
    "    while(status == \"IN_PROGRESS\"):\n",
    "        \n",
    "        # time lag before reporting status\n",
    "        time.sleep(5)                                         \n",
    "        response = client.get_document_analysis(JobId=jobId)\n",
    "        \n",
    "        # job-status of the response object\n",
    "        status = response[\"JobStatus\"]                        \n",
    "        print(\"Job status: {}\".format(status))\n",
    "    \n",
    "    return status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getJobResults(jobId:str) -> list:\n",
    "    \"\"\"\n",
    "    Returns the contents of the Textract job, after job status is completed\n",
    "    \"\"\"\n",
    "    # initialize list object to track pages read\n",
    "    pages = []                    \n",
    "\n",
    "    client = boto3.client('textract')\n",
    "    response = client.get_document_analysis(JobId=jobId)\n",
    "    \n",
    "    # add first page response to list (length of pages will be arbitrary) \n",
    "    pages.append(response)      \n",
    "    print(\"Resultset page recieved: {}\".format(len(pages)))\n",
    "    \n",
    "    # if NextToken present we have a pointer to page (e.g. Response -> Page) \n",
    "    nextToken = None\n",
    "    if('NextToken' in response):\n",
    "        nextToken = response['NextToken']\n",
    "    \n",
    "    # iterate through the pages and append to response figure (assuming nextToken not None)\n",
    "    while(nextToken):\n",
    "        response = client.get_document_analysis(JobId=jobId, NextToken=nextToken)\n",
    "        pages.append(response)\n",
    "        print(\"Resultset page recieved: {}\".format(len(pages)))\n",
    "        \n",
    "        # move along linked-list for presence of NextToken response\n",
    "        nextToken = None\n",
    "        if('NextToken' in response):\n",
    "            nextToken = response['NextToken']\n",
    "    \n",
    "    # return amalgamation of all page responses \n",
    "    return pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runJob(bucket:str, key:str):\n",
    "    \"\"\"\n",
    "    Function designed to call an AWS Textract job (implements helper function above)\n",
    "    \"\"\"\n",
    "    jobId = startJob(bucket, key)   \n",
    "    print(\"Started job with id: {}\".format(jobId))\n",
    "\n",
    "    # if job is complete on AWS return page responses \n",
    "    if(isJobComplete(jobId)):\n",
    "        response = getJobResults(jobId)\n",
    "        \n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Extraction Scripts (Key-Value Pairs)\n",
    "**The content was modified from AWS to extract key-value pairs in form documents from Block objects that are stored in a map. (refer to [URL](https://docs.aws.amazon.com/textract/latest/dg/examples-extract-kvp.html))**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_value_block(key_block, value_map):\n",
    "    \"\"\"\n",
    "    Retrieving value block from AWS textract job, this contains the value text \n",
    "    \"\"\"\n",
    "    # iterate through the key blocks in the FORM relationships (should have a VALUE and CHILD type, n=2)\n",
    "    for relationship in key_block['Relationships']:\n",
    "        \n",
    "        # if our key block object type is a VALUE we examine the relationship ID\n",
    "        # NOTE WE SHOULD HAVE ONLY ONE ID FOR THE VALUE RELATIONSHIP TYPE\n",
    "        if relationship['Type'] == 'VALUE':\n",
    "            \n",
    "            # singular ID item stored in list object (return value block object)\n",
    "            for value_id in relationship['Ids']:\n",
    "                value_block = value_map[value_id]\n",
    "            \n",
    "    # return all corresponding value series\n",
    "    return value_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kv_relationship(key_map, value_map, block_map):\n",
    "    \"\"\"\n",
    "    Retrieving the Key-Value relationship from FORM OCR Textract \n",
    "    \"\"\"\n",
    "    # initialize key-map dictionary for lineitems and corresponding accounting values\n",
    "    key_value_map = {}\n",
    "    \n",
    "    # unpack the key_map to retrieve the block id and key names\n",
    "    for block_id, key_block in key_map.items():\n",
    "\n",
    "        # retrieve value block provided the key_block from each block id\n",
    "        value_block = find_value_block(key_block, value_map)\n",
    "\n",
    "        # get text value from key and value blocks\n",
    "        key = get_text(key_block, block_map)\n",
    "        val = get_text(value_block, block_map)\n",
    "        \n",
    "        # map the key and value pairs (e.g. {'Total Assets':'$ 189,232'})\n",
    "        key_value_map[key] = val\n",
    "        \n",
    "    return key_value_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(result, blocks_map):\n",
    "    \"\"\"\n",
    "    Retrieving text values from given block object\n",
    "    \"\"\"\n",
    "    # initialize container for text\n",
    "    text = ''\n",
    "    \n",
    "    # if relationships header exists we can extract CHILD header\n",
    "    if 'Relationships' in result:\n",
    "        \n",
    "        # relationship maps to a list (iterate through to reveal a dictionary)\n",
    "        # e.g. 'Relationships' : [{'Type' : 'CHILD', 'Ids': ['e2b3b12f-ebb7-4f6e-914f-97b315672530']}]\n",
    "        for relationship in result['Relationships']:\n",
    "            \n",
    "            # if relationship type is CHILD we explore job-id (indicates good fit)\n",
    "            if relationship['Type'] == 'CHILD':\n",
    "                \n",
    "                # iterate through Ids list\n",
    "                for child_id in relationship['Ids']:\n",
    "                    \n",
    "                    # select corresponding CHILD_ID from block map, this is sub-dictionary\n",
    "                    word = blocks_map[child_id]\n",
    "                    \n",
    "                    # if block type is a word then we append with a space\n",
    "                    if word['BlockType'] == 'WORD':\n",
    "                        text += word['Text'] + ' '\n",
    "                        \n",
    "                    # if block type is a selection element (e.g. an option button/mark)\n",
    "                    # note we treat these cases with an X to denote an optional field \n",
    "                    if word['BlockType'] == 'SELECTION_ELEMENT':\n",
    "                        if word['SelectionStatus'] == 'SELECTED':\n",
    "                            text += 'X '    \n",
    "    \n",
    "    # return string corresponding with word \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR Wrapper Functions\n",
    "**The scripts perform an OCR job from AWS Textract, and returning well formated data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trp2df(table:trp.Table) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function designed to convert a trp table into a dataframe Complexity -> O(n^2) approx.\n",
    "    ------------------------------------------------------------------------------------------\n",
    "    Input\n",
    "        :param table: (type trp.Table)\n",
    "            A trp table object parsed from a pdf using AWS Textract  \n",
    "    \n",
    "    Output\n",
    "        :return: type pandas.DataFrame\n",
    "            A DataFrame object that is constructed by deconstructed a Textract trp table\n",
    "    \"\"\"\n",
    "    N = len(table.rows)               # number of rows in table\n",
    "    M = len(table.rows[0].cells)      # number of columns in table\n",
    "    arr = [0]*N                       # initialize matrix container\n",
    "    \n",
    "    # iterate through each row within the provided table\n",
    "    for row in np.arange(N):\n",
    "        \n",
    "        # strip the text from the cell references to construct (N X M) matrix\n",
    "        arr[row] = [table.rows[row].cells[col].text.strip() for col in np.arange(M)]    # move column-wise to get text\n",
    "    \n",
    "    df = pd.DataFrame(arr)\n",
    "    \n",
    "    # remove columns that are completely empty\n",
    "    empty_cols = [col for col in df.columns if (df[col] == '').all()]\n",
    "    df = df.drop(empty_cols, axis=1)\n",
    "\n",
    "    # reset the column names (avoid the column names)\n",
    "    df.columns = np.arange(df.columns.size)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dollar_sign(row):\n",
    "    \"\"\"\n",
    "    Determines if there exists a dollar sign present within a given row\n",
    "    ------------------------------------------------------------------------------------------\n",
    "    Input:\n",
    "        :param: row (type nd.array)\n",
    "            A given row from a dataframe\n",
    "    Return:\n",
    "        This function returns a bollean sequence\n",
    "    \"\"\"\n",
    "    \n",
    "    def re_dollar_check(x):\n",
    "        # we search for the presence of a dollar sign ($) in a string followed by character\n",
    "        dollar_search = re.search('\\$[^\\]]+', x, flags=re.IGNORECASE)\n",
    "        \n",
    "        if dollar_search is not None: return True\n",
    "        return False\n",
    "\n",
    "    vFunc = np.vectorize(re_dollar_check)      # vectorize function to apply to numpy array\n",
    "    cleanValue = vFunc(row)                    # apply vector function\n",
    "    \n",
    "    # search each vector return for presence of True\n",
    "    # if True we have found a dollar '$' character\n",
    "    series = np.argwhere(cleanValue == True)\n",
    "    if len(series) > 0: \n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_balance_sheet(df:pd.DataFrame) -> tuple:\n",
    "    \"\"\"\n",
    "    Determines if a read table is a balance sheet term\n",
    "    ------------------------------------------------------------------------------------------\n",
    "    Input:\n",
    "        :param: df (type pd.DataFrame)\n",
    "            A given dataframe table\n",
    "    Return:\n",
    "        This function returns a dataframe that fits the balance sheet parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    # number of columns in dataframe\n",
    "    n = df.columns.size\n",
    "    \n",
    "    ##############################################################\n",
    "    #                           NOTES\n",
    "    #          a good dataframe should have 2-3 columns\n",
    "    #      anything more or less is a reading error we ignore\n",
    "    ##############################################################\n",
    "\n",
    "    # if the dataframe has more than 3 columns then we most likley have an issue in parsing, avoid\n",
    "    if n > 3: \n",
    "        return None\n",
    "\n",
    "    elif n > 1:\n",
    "\n",
    "        ##############################\n",
    "        # Balance Sheet Assummptions\n",
    "        ##############################\n",
    "\n",
    "        # this is the first column which should have all line items (e.g. Cash, Total Assets, Total Liabilites)\n",
    "        lineIndex = df.columns[0]\n",
    "\n",
    "        # check for the word \"cash\" in a string at the begining, ignoring case sensitivity (asset check)\n",
    "        assetCheck = df[lineIndex].str.contains('^Cash|asset', regex=True, flags=re.IGNORECASE)\n",
    "\n",
    "        # check for the word \"Liabilities\" in a string at the end, ignoring case sensitivity (liability check)\n",
    "        debtCheck1 = df[lineIndex].str.contains('liabilities|liability', regex=True, flags=re.IGNORECASE)\n",
    "#         debtCheck2 = df[lineIndex].str.contains('liability$|^liability', regex=True, flags=re.IGNORECASE)\n",
    "\n",
    "        # check for the presence of $ sign, we assume the balance sheet items should have at least one $ sign\n",
    "        # this check is used to avoid reading the table of contents, which was flagged in prior reads\n",
    "        dollarCheck = df.apply(check_dollar_sign, axis=1)\n",
    "\n",
    "        ##############################\n",
    "        # Balance Sheet Determination\n",
    "        ##############################\n",
    "\n",
    "        check1 = df[assetCheck == True].empty                  # check for asset table\n",
    "        check2 = df[debtCheck1].empty                          # check for liability & equity table\n",
    "        check3 = df[dollarCheck == True].empty                 # check for presence of '$' sign  \n",
    "\n",
    "        # make sure the cash term appears toward the top of the balance sheet\n",
    "        if np.argmax(assetCheck==True) < assetCheck.shape[0]/2:\n",
    "\n",
    "            # if either asset term or liability term is found, with a $ sign we append the dataframe\n",
    "            if (check1 == False or check2 == False) and (check3 == False):\n",
    "                return (df, check1, check2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTable(response:list) -> tuple:\n",
    "    \"\"\"\n",
    "    Function to transform AWS Textract object to a dataframe, by searching for tables\n",
    "     ------------------------------------------------------------------------------------------\n",
    "    Input\n",
    "        :param response: (type list)\n",
    "            An AWS Textract response object corresponding to pages of a given document page \n",
    "    \n",
    "    Output\n",
    "        :return: type tuple\n",
    "            A (3x1) tuple is returned, storing the concated dataframe at the first index, and the accompanying \n",
    "            trp page objects for where the balance sheet was determined to reside at the second index\n",
    "    \"\"\"\n",
    "    \n",
    "    catDF = []          # in the event multiple tables detected on one page (concat them)\n",
    "    page_series = []    # keep track of page objects where balance sheet was flagged\n",
    "    page_nums = []      # keep track of page numbers where balance sheet was found\n",
    "    page_count = 0\n",
    "    \n",
    "    tb_diff_c1 = 0      # flag to help indicate if tables, immediately precede one another \n",
    "    tb_diff_c2 = 0\n",
    "    \n",
    "    prior_c1 = True     # keep track of previous asset flag \n",
    "    prior_c2 = True     # keep track of previous liability flag\n",
    "    \n",
    "    # format the Textract response type \n",
    "    doc = trp.Document(response)\n",
    "    \n",
    "    # iterate through document pages\n",
    "    for page in doc.pages:\n",
    "        \n",
    "        # itterate through page tables\n",
    "        for table in page.tables: \n",
    "            \n",
    "            # convert trp-table into dataframe object\n",
    "            df = trp2df(table)\n",
    "            \n",
    "            # retrieve balance sheet from table\n",
    "            balance_sheet = get_balance_sheet(df)\n",
    "            \n",
    "            if type(balance_sheet) is tuple:\n",
    "                \n",
    "                bs, c1, c2 = balance_sheet      # unpack the return object\n",
    "                \n",
    "                # we append pages since asset and liablility tables are often seperate\n",
    "                # there is no loss of generality if asset and liability terms are in one table\n",
    "                catDF.append(bs)                \n",
    "\n",
    "                # we want to keep track of pages that have been deemed as balance sheet\n",
    "                # this helps speed up the runtime for Text, Forms and PNG\n",
    "                if page not in page_series:\n",
    "                    page_series.append(page)      \n",
    "                    page_nums.append(page_count)\n",
    "                \n",
    "                ##############################\n",
    "                # Flag for split tables \n",
    "                ##############################\n",
    "                \n",
    "                # indicates no liability term read, no previous asset term was read\n",
    "                # we are currenlty reading the asset term of the balance sheet\n",
    "                if c2 == True and prior_c1 == True and prior_c2 == True and c1 == False:\n",
    "                    print('Balance sheet line items have been split across table\\n')\n",
    "                    prior_c1 = False\n",
    "                    tb_diff_c1 = 0\n",
    "                    \n",
    "                # indicates no asset term read, no previous asset term was read\n",
    "                # we are currenlty reading the liability term of the balance sheet\n",
    "                elif c1 == True and prior_c1 == True and c2 == False:\n",
    "                    print('Asset line items may be read after liability line items\\n')\n",
    "                    prior_c2 = False\n",
    "                    tb_diff_c2 = 0\n",
    "                    \n",
    "                ##############################\n",
    "                # Balance Sheet Exportation \n",
    "                ##############################\n",
    "\n",
    "                # 1) indicates both assets and liability terms were found in table\n",
    "                if (c2 == False and c1 == False) or (c2 == False and prior_c1 == False and tb_diff_c1 == 1):\n",
    "                    return (pd.concat(catDF), page_series, page_nums)\n",
    "                \n",
    "                # 2) indicates liability term read before assets \n",
    "                elif prior_c2 == False and c1 == False and tb_diff_c2 == 1:\n",
    "                    catDF.reverse()\n",
    "                    return (pd.concat(catDF), page_series, page_nums)\n",
    "                    \n",
    "                else: pass\n",
    "            \n",
    "            # table scope iteration\n",
    "            tb_diff_c1 += 1\n",
    "            tb_diff_c2 += 1\n",
    "        \n",
    "        # page scope iteration\n",
    "        page_count += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readPNG(pages:list, png_path:str, bucket='ran-s3-systemic-risk') -> tuple:\n",
    "    \"\"\"\n",
    "    Function to transform AWS Textract object to a dataframe, by searching for tables\n",
    "     ------------------------------------------------------------------------------------------\n",
    "    Input\n",
    "        :param response: (type list)\n",
    "            \n",
    "    \n",
    "    Output\n",
    "        :return: type tuple\n",
    "          \n",
    "    \"\"\"\n",
    "    subfolder = png_path.split('/')[-2]      # subfolder where PNG files are stored\n",
    "    \n",
    "    # construct PNG directories with relevant pages\n",
    "    textract_paths = [png_path + subfolder + '-p{}.png'.format(idx) for idx in pages]\n",
    "    \n",
    "    ##############################\n",
    "    # Initialzie Variables\n",
    "    ##############################\n",
    "            \n",
    "    catDF = []          \n",
    "    prior_c1 = True     \n",
    "    prior_c2 = True     \n",
    "    \n",
    "    # path iterates through each png image matching the page numbers found in PDFs\n",
    "    for path in textract_paths:\n",
    "        \n",
    "        try:\n",
    "            # temporary data frame object for balance sheet information\n",
    "            res = runJob(bucket, path)\n",
    "            \n",
    "            # if Textract job did not fail we continue extraction\n",
    "            if res[0]['JobStatus'] != 'FAILED':\n",
    "\n",
    "                # format the Textract response type \n",
    "                doc = trp.Document(res)\n",
    "\n",
    "                # iterate through document pages\n",
    "                for page in doc.pages:\n",
    "                    \n",
    "                    # itterate through page tables\n",
    "                    for table in page.tables: \n",
    "                        \n",
    "                        # convert trp-table into dataframe object\n",
    "                        df = trp2df(table)\n",
    "                        \n",
    "                        # retrieve balance sheet from table\n",
    "                        balance_sheet = get_balance_sheet(df)\n",
    "                        \n",
    "                        if type(balance_sheet) is tuple:\n",
    "                \n",
    "                            bs, c1, c2 = balance_sheet      # unpack the return object\n",
    "                            \n",
    "                            # we append pages since asset and liablility tables are often seperate\n",
    "                            # there is no loss of generality if asset and liability terms are in one table\n",
    "                            catDF.append(bs)            \n",
    "                            \n",
    "                            ##############################\n",
    "                            # Flag for split tables \n",
    "                            ##############################\n",
    "\n",
    "                            # indicates no asset or liability term was read\n",
    "                            # we are currenlty reading the asset term of the balance sheet\n",
    "                            if c2 == True and prior_c1 == True and prior_c2 == True and c1 == False:\n",
    "                                print('Balance sheet line items have been split across table\\n')\n",
    "                                prior_c1 = False\n",
    "\n",
    "                            # indicates no asset term read, no previous asset term was read\n",
    "                            # we are currenlty reading the liability term of the balance sheet\n",
    "                            elif c1 == True and prior_c1 == True and c2 == False:\n",
    "                                print('Asset line items may be read after liability line items\\n')\n",
    "                                prior_c2 = False\n",
    "\n",
    "                            ##############################\n",
    "                            # Balance Sheet Exportation \n",
    "                            ##############################\n",
    "\n",
    "                            # 1) indicates both assets and liability terms were found in table\n",
    "                            if (c2 == False and c1 == False) or (c2 == False and prior_c1 == False):\n",
    "                                return pd.concat(catDF)\n",
    "\n",
    "                            # 2) indicates liability term read before assets \n",
    "                            elif prior_c2 == False and c1 == False:\n",
    "                                catDF.reverse()\n",
    "                                return pd.concat(catDF)\n",
    "\n",
    "                            else: pass\n",
    "            \n",
    "        # broad exeption to catch Textract parsing errors\n",
    "        except:pass\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readForm(doc_pages:list) -> dict:\n",
    "    \"\"\"\n",
    "    Function to transform AWS Textract object to a dictionary, by searching for key value pairs\n",
    "    ------------------------------------------------------------------------------------------\n",
    "    Input\n",
    "        :param doc_pages: (type list)\n",
    "            TRP page(s) for a AWS Textract response object corresponding to pages of a given document page \n",
    "    \n",
    "    Output\n",
    "        :return: type dict\n",
    "            A python dictionary that maps KEYS (line items) with VALUES (corresponding records) for broker\n",
    "            dealers balance sheet (e.g. {'Cash and cash equivalents : $ 12,513})\n",
    "    \"\"\"\n",
    "    \n",
    "    # initializing dictionary maps for KEY and VALUE pairs\n",
    "    key_map = {}\n",
    "    value_map = {}\n",
    "    block_map = {}\n",
    "\n",
    "    # iterate through document pages\n",
    "    for page in doc_pages:\n",
    "\n",
    "        # itterate through page tables\n",
    "        for block in page.blocks: \n",
    "\n",
    "            # store the block id in map to retrive information later\n",
    "            block_id = block['Id']\n",
    "            block_map[block_id] = block\n",
    "\n",
    "            # if Key-value set has been seen we deconstruct each KEY and VALUE map\n",
    "            if block['BlockType'] == \"KEY_VALUE_SET\":\n",
    "\n",
    "                # if KEY is labeled as entity type then we found Key, else we found VALUE\n",
    "                if 'KEY' in block['EntityTypes']:\n",
    "                    key_map[block_id] = block\n",
    "                else:\n",
    "                    value_map[block_id] = block\n",
    "    \n",
    "    # convert block objects to text dictionary map\n",
    "    return get_kv_relationship(key_map, value_map, block_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readText(doc_pages:list) -> dict:\n",
    "    \"\"\"\n",
    "    Function to transform AWS Textract object to a dictionary of text values and confidence \n",
    "    ------------------------------------------------------------------------------------------\n",
    "    Input\n",
    "        :param doc_pages: (type list)\n",
    "            TRP page(s) for a AWS Textract response object corresponding to pages of a given document page\n",
    "    \n",
    "    Output\n",
    "        :return: type dict\n",
    "            A python dictionary that maps TEXT (line items) with corresponding confidence figures as reported\n",
    "            by AWS Textract object (e.g. {'Cash and cash equivalents : 99.97891})\n",
    "    \"\"\"\n",
    "    # initializing dictionary maps for text\n",
    "    text_map = {}\n",
    "    \n",
    "    # iterate through document pages\n",
    "    for page in doc_pages:\n",
    "        \n",
    "        # itterate through page tables\n",
    "        for block in page.blocks: \n",
    "            \n",
    "            # if our block type is a line, we map the line text and confidence\n",
    "            if block['BlockType'] == \"LINE\":\n",
    "                text_map[block['Text']] = block['Confidence']\n",
    "    \n",
    "    # return completed text to confidence map\n",
    "    return text_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Balance Sheet information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textractParse(pdf_path:str, png_path:str, bucket:str) -> dict:\n",
    "    \"\"\"\n",
    "    Function runs a Textract job and saves Balance Sheet information to .csv file in s3 folder \n",
    "    \"\"\"\n",
    "    errors = ''\n",
    "    \n",
    "    # temporary data frame object for balance sheet information\n",
    "    res = runJob(bucket, pdf_path)\n",
    "    \n",
    "    # if Textract job did not fail we continue extraction\n",
    "    if res[0]['JobStatus'] != 'FAILED':\n",
    "\n",
    "        # perform OCR and return balance sheet with corresponding page object(s)\n",
    "        tb_response = readTable(res)           \n",
    "        \n",
    "        # checks for type of return, if none then we log an error\n",
    "        if type(tb_response) == tuple:\n",
    "            \n",
    "            # deconstruct the table response tuple into dataframe and page object parts\n",
    "            df1, page_obj, page_num = tb_response\n",
    "            print('\\nPage number(s) for extraction in PNG are {}\\n'.format(page_num))\n",
    "            \n",
    "            # try to extract from a PNG (we can still return a None here)\n",
    "            df2 = readPNG(page_num, png_path)\n",
    "            \n",
    "            # provided balance sheet page number we select FORM and TEXT data\n",
    "            forms_data = readForm(page_obj)      \n",
    "            text_data = readText(page_obj)        \n",
    "            \n",
    "            print('\\nTextract-PDF dataframe')\n",
    "            print(df1)\n",
    "            \n",
    "            print('\\nTextract-PNG dataframe')\n",
    "            print(df2)\n",
    "            \n",
    "            return (df1, df2, forms_data, text_data, None)\n",
    "        else:\n",
    "            error = 'No Balance Sheet found, or parsing error'\n",
    "            return (None, None, None, None, error)\n",
    "    else:\n",
    "        error = 'Could not parse, JOB FAILED'\n",
    "        return (None, None, None, None, error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main File Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing OCR for 87634-2020-02-27.csv\n",
      "87634-2020-02-27.csv has been downloaded\n",
      "\n",
      "Performing OCR for 1616344-2020-02-27.csv\n",
      "1616344-2020-02-27.csv has been downloaded\n",
      "\n",
      "Performing OCR for 1616344-2021-02-25.csv\n",
      "1616344-2021-02-25.csv has been downloaded\n",
      "\n",
      "Performing OCR for 318336-2005-03-01.csv\n",
      "318336-2005-03-01.csv has been downloaded\n",
      "\n",
      "Performing OCR for 318336-2018-03-01.csv\n",
      "318336-2018-03-01.csv has been downloaded\n",
      "\n",
      "Performing OCR for 91154-2015-03-02.csv\n",
      "91154-2015-03-02.csv has been downloaded\n",
      "\n",
      "Performing OCR for 91154-2019-03-05.csv\n",
      "91154-2019-03-05.csv has been downloaded\n",
      "\n",
      "Performing OCR for 89562-2006-01-30.csv\n",
      "89562-2006-01-30.csv has been downloaded\n",
      "\n",
      "Performing OCR for 356628-2006-03-02.csv\n",
      "356628-2006-03-02.csv has been downloaded\n",
      "\n",
      "Performing OCR for 356628-2007-03-01.csv\n",
      "356628-2007-03-01.csv has been downloaded\n",
      "\n",
      "Performing OCR for 356628-2008-02-29.csv\n",
      "356628-2008-02-29.csv has been downloaded\n",
      "\n",
      "Performing OCR for 808379-2015-03-02.csv\n",
      "808379-2015-03-02.csv has been downloaded\n",
      "\n",
      "Performing OCR for 895502-2004-08-05.csv\n",
      "895502-2004-08-05.csv has been downloaded\n",
      "\n",
      "Performing OCR for 895502-2009-12-30.csv\n",
      "895502-2009-12-30.csv has been downloaded\n",
      "\n",
      "Performing OCR for 276523-2006-08-08.csv\n",
      "276523-2006-08-08.csv has been downloaded\n",
      "\n",
      "Performing OCR for 1146184-2021-02-25.csv\n",
      "Started job with id: d5a2fb251d920c3643b66fa8bbb30632912b646d469e51413de8fb7c63db7ab7\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: SUCCEEDED\n",
      "Resultset page recieved: 1\n",
      "Resultset page recieved: 2\n",
      "Resultset page recieved: 3\n",
      "Resultset page recieved: 4\n",
      "Resultset page recieved: 5\n",
      "Resultset page recieved: 6\n",
      "Resultset page recieved: 7\n",
      "Resultset page recieved: 8\n",
      "Resultset page recieved: 9\n",
      "\n",
      "Page number(s) for extraction in PNG are [7]\n",
      "\n",
      "Started job with id: f4a3a214a25589f4f3d93751b06fa0fd10736f3a84256afd720770b470953922\n",
      "Job status: IN_PROGRESS\n",
      "Job status: SUCCEEDED\n",
      "Resultset page recieved: 1\n",
      "\n",
      "Textract-PDF dataframe\n",
      "                                                    0         1\n",
      "0                                        Other assets       165\n",
      "1                                                              \n",
      "2                    LIABILITIES AND MEMBER'S CAPITAL          \n",
      "3                                        Liabilities:          \n",
      "4   Securities sold, not yet purchased, at fair value  $ 57,506\n",
      "5      Securities sold under agreements to repurchase     4,472\n",
      "6   Payable to brokers, dealers, and clearing orga...     2,847\n",
      "7             Loans and interest payable to affiliate     1,653\n",
      "8                                   Securities loaned       867\n",
      "9                                   Other liabilities       342\n",
      "10                              Payable to affiliates       168\n",
      "11                                  Total liabilities    67,855\n",
      "12                                   Member's capital     3,149\n",
      "13             Total liabilities and member's capital  $ 71,004\n",
      "\n",
      "Textract-PNG dataframe\n",
      "                                                    0         1\n",
      "0                                                              \n",
      "1                                        Other assets       165\n",
      "2                                                              \n",
      "3                    LIABILITIES AND MEMBER'S CAPITAL          \n",
      "4                                        Liabilities:          \n",
      "5   Securities sold, not yet purchased, at fair value  $ 57,506\n",
      "6      Securities sold under agreements to repurchase     4,472\n",
      "7   Payable to brokers, dealers, and clearing orga...     2,847\n",
      "8             Loans and interest payable to affiliate     1,653\n",
      "9                                   Securities loaned       867\n",
      "10                                  Other liabilities       342\n",
      "11                              Payable to affiliates       168\n",
      "12                                  Total liabilities    67,855\n",
      "13                                   Member's capital     3,149\n",
      "14             Total liabilities and member's capital  $ 71,004\n",
      "{'CITADEL SECURITIES LLC': 99.66032409667969, 'Statement of Financial Condition': 99.72899627685547, '(Expressed in U.S. dollars in millions)': 99.89763641357422, 'ASSETS': 99.38446044921875, 'As of December 31, 2020': 99.83881378173828, 'Assets:': 99.93624114990234, 'Cash': 99.91136169433594, '$': 99.84235382080078, '523': 99.95812225341797, 'Securities owned, at fair value': 99.89781951904297, '66,707': 99.28941345214844, 'Securities borrowed': 99.94015502929688, '1,628': 98.36713409423828, 'Receivable from brokers and dealers': 99.91773986816406, '841': 99.85662078857422, 'Receivable from clearing organizations and custodian': 99.8318862915039, '648': 99.94789123535156, 'Securities purchased under agreements to resell': 99.94621276855469, '492': 99.83527374267578, 'Other assets': 99.93704223632812, '165': 99.87158203125, 'Total assets': 99.89086151123047, '71,004': 99.52886199951172, \"LIABILITIES AND MEMBER'S CAPITAL\": 99.60159301757812, 'Liabilities:': 99.2642593383789, 'Securities sold, not yet purchased, at fair value': 99.93950653076172, '57,506': 99.64641571044922, 'Securities sold under agreements to repurchase': 99.89151000976562, '4,472': 99.75045013427734, 'Payable to brokers, dealers, and clearing organizations': 99.84611511230469, '2,847': 99.66124725341797, 'Loans and interest payable to affiliate': 99.94601440429688, '1,653': 99.30206298828125, 'Securities loaned': 99.92967224121094, '867': 99.78164672851562, 'Other liabilities': 99.94683837890625, '342': 99.8006820678711, 'Payable to affiliates': 99.91090393066406, '168': 99.87420654296875, 'Total liabilities': 99.88217163085938, '67,855': 99.72492218017578, \"Member's capital\": 99.82756042480469, '3,149': 99.49358367919922, \"Total liabilities and member's capital\": 99.92195129394531, 'See notes to statement of financial condition.': 99.86280059814453, '1': 99.41814422607422}\n",
      "-----------------------------------------------------\n",
      "Saved 1146184-2021-02-25.csv file to s3 bucket\n",
      "\n",
      "\n",
      "Finished performing OCR on parsed FOCUS reports.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Amazon Textract client and Sagemaker session\n",
    "    textract = boto3.client('textract')\n",
    "    s3 = boto3.client('s3')\n",
    "    session = Session()\n",
    "    \n",
    "    # initiate s3 bucket and corresponding data/output folder\n",
    "    bucket = 'ran-s3-systemic-risk'\n",
    "    \n",
    "    data_png_folder = 'Input/X-17A-5-PNG-SUBSETS/'\n",
    "    data_pdf_folder = 'Input/X-17A-5-PDF-SUBSETS/'\n",
    "    \n",
    "    output_png_folder = 'Output/X-17A-5-PNG-RAW/'\n",
    "    output_pdf_folder = 'Output/X-17A-5-PDF-RAW/'\n",
    "    \n",
    "    temp_folder = 'Temp/'\n",
    "    \n",
    "    # csv directory where we store balance sheet information \n",
    "    output_png_csvs = np.array(session.list_s3_files(bucket, output_png_folder))\n",
    "    output_pdf_csvs = np.array(session.list_s3_files(bucket, output_pdf_folder))\n",
    "    \n",
    "    # temp directory where JSON files is stored\n",
    "    temp = np.array(session.list_s3_files(bucket, temp_folder))\n",
    "    \n",
    "    # pdf directory where we store the broker-dealer information \n",
    "    pdf_files = np.array(session.list_s3_files(bucket, data_pdf_folder))[1:]\n",
    "    png_files = np.array(session.list_s3_files(bucket, data_png_folder))[1:]\n",
    "    png_file_directory = list(set((map(lambda x: '/'.join(x.split('/')[:-1]), png_files))))\n",
    "    \n",
    "    # ===========================================================================\n",
    "    # Load in Temp JSON files if present (FORM, TEXT, ERROR)\n",
    "    # ===========================================================================\n",
    "    \n",
    "    if 'Temp/X17A5-FORMS.json' in temp:\n",
    "        # retrieving downloaded files from s3 bucket\n",
    "        s3.download_file(bucket, 'Temp/X17A5-FORMS.json', 'temp1.json')\n",
    "        \n",
    "        # read data on KEY-VALUE dictionary (i.e Textract FORMS) \n",
    "        with open('temp1.json', 'r') as f: forms_dictionary = json.loads(f.read())\n",
    "        \n",
    "        # remove local files for JSON\n",
    "        os.remove('temp1.json')\n",
    "    else:\n",
    "        forms_dictionary = {}\n",
    "    \n",
    "    if 'Temp/X17A5-TEXT.json' in temp:\n",
    "        # retrieving downloaded files from s3 bucket\n",
    "        s3.download_file(bucket, 'Temp/X17A5-TEXT.json', 'temp2.json')\n",
    "        \n",
    "        # read data on TEXT-Confidence dictionary\n",
    "        with open('temp2.json', 'r') as f: text_dictionary = json.loads(f.read())  \n",
    "            \n",
    "        # remove local files for JSON\n",
    "        os.remove('temp2.json')\n",
    "    else:\n",
    "        text_dictionary = {}\n",
    "    \n",
    "    if 'Temp/ERROR-TEXTRACT.json' in temp:\n",
    "        # retrieving downloaded files from s3 bucket\n",
    "        s3.download_file(bucket, 'Temp/ERROR-TEXTRACT.json', 'temp3.json')\n",
    "        \n",
    "        # read data on errors derived from Textract\n",
    "        with open('temp3.json', 'r') as f: error_dictionary = json.loads(f.read()) \n",
    "            \n",
    "        # remove local files for JSON\n",
    "        os.remove('temp3.json')\n",
    "    else:\n",
    "        error_dictionary = {}\n",
    "    \n",
    "    # ===========================================================================\n",
    "    # Perform Textract analysis on PDFs and PNGs\n",
    "    # ===========================================================================\n",
    "    \n",
    "    # e.g. ['Input/X-17A-5-PDF-SUBSETS/42352-2012-02-29-subset.pdf'] otherwise pdf_files (full sample)\n",
    "    select_sample = [\n",
    "        'Input/X-17A-5-PDF-SUBSETS/87634-2020-02-27-subset.pdf', \n",
    "        'Input/X-17A-5-PDF-SUBSETS/1616344-2020-02-27-subset.pdf',\n",
    "        'Input/X-17A-5-PDF-SUBSETS/1616344-2021-02-25-subset.pdf',\n",
    "        'Input/X-17A-5-PDF-SUBSETS/318336-2005-03-01-subset.pdf',\n",
    "        'Input/X-17A-5-PDF-SUBSETS/318336-2018-03-01-subset.pdf',\n",
    "        'Input/X-17A-5-PDF-SUBSETS/91154-2015-03-02-subset.pdf', \n",
    "        'Input/X-17A-5-PDF-SUBSETS/91154-2019-03-05-subset.pdf',\n",
    "        'Input/X-17A-5-PDF-SUBSETS/89562-2006-01-30-subset.pdf',\n",
    "        'Input/X-17A-5-PDF-SUBSETS/356628-2006-03-02-subset.pdf',\n",
    "        'Input/X-17A-5-PDF-SUBSETS/356628-2007-03-01-subset.pdf', \n",
    "        'Input/X-17A-5-PDF-SUBSETS/356628-2008-02-29-subset.pdf',\n",
    "        'Input/X-17A-5-PDF-SUBSETS/808379-2015-03-02-subset.pdf',\n",
    "        'Input/X-17A-5-PDF-SUBSETS/895502-2004-08-05-subset.pdf',\n",
    "        'Input/X-17A-5-PDF-SUBSETS/895502-2009-12-30-subset.pdf',\n",
    "        'Input/X-17A-5-PDF-SUBSETS/276523-2006-08-08-subset.pdf',\n",
    "        'Input/X-17A-5-PDF-SUBSETS/1146184-2021-02-25-subset.pdf'\n",
    "                    ]\n",
    "\n",
    "    for pdf_paths in select_sample:\n",
    "        \n",
    "        # baseFile name to name export .csv file e.g. 1224385-2004-03-01.csv\n",
    "        basefile = pdf_paths.split('/')[-1].split('-subset')[0]\n",
    "        fileName = basefile + '.csv'\n",
    "        print('\\nPerforming OCR for {}'.format(fileName))\n",
    "        \n",
    "        # if file is not found in directory we extract the balance sheet\n",
    "        # WE LOOK TO AVOID RE-RUNNING OLD TEXTRACT PARSES TO SAVE TIME\n",
    "        if (output_pdf_folder + fileName not in output_pdf_csvs):\n",
    "            \n",
    "            # run Textract OCR job and extract the parsed data \n",
    "            png_paths = data_png_folder + basefile + '/'\n",
    "            df1, df2, forms_data, text_data, error = textractParse(pdf_paths, png_paths, bucket)\n",
    "\n",
    "            # if no error is reported we save FORMS, TEXT, DataFrame\n",
    "            if error is None:\n",
    "\n",
    "                # store accompanying information for JSONs\n",
    "                forms_dictionary[basefile] = forms_data\n",
    "                text_dictionary[basefile]  = text_data\n",
    "                print(text_data)\n",
    "                \n",
    "                # writing data frame to .csv file\n",
    "                df1.to_csv(fileName, index=False)\n",
    "\n",
    "                # save contents to AWS S3 bucket\n",
    "                with open(fileName, 'rb') as data:\n",
    "                    s3.put_object(Bucket=bucket, Key=output_pdf_folder + fileName, Body=data)\n",
    "                \n",
    "                # writing data frame to .csv file extracted from PNG\n",
    "                if df2 is not None:\n",
    "                    df2.to_csv(fileName, index=False)\n",
    "                    \n",
    "                    with open(fileName, 'rb') as data:\n",
    "                        s3.put_object(Bucket=bucket, Key=output_png_folder + fileName, Body=data)\n",
    "    \n",
    "                # remove local file after it has been created\n",
    "                os.remove(fileName)\n",
    "\n",
    "                print('-----------------------------------------------------')\n",
    "                print('Saved {} file to s3 bucket'.format(fileName))\n",
    "            \n",
    "            else:\n",
    "                error_dictionary[basefile] = error\n",
    "                \n",
    "        else:\n",
    "            print('{} has been downloaded'.format(fileName))\n",
    "    \n",
    "    # ===========================================================================\n",
    "    # Save JSON files for updated figures (FORM, TEXT, ERROR)\n",
    "    # ===========================================================================\n",
    "    \n",
    "    # write to a JSON file for FORMS \n",
    "    with open('/home/ec2-user/SageMaker/SEC_X17A5/temp/X17A5-FORMS.json', 'w') as file: \n",
    "        json.dump(forms_dictionary, file)\n",
    "        file.close()\n",
    "    \n",
    "    # save contents to AWS S3 bucket\n",
    "    with open('/home/ec2-user/SageMaker/SEC_X17A5/temp/X17A5-FORMS.json', 'rb') as data: \n",
    "        s3.upload_fileobj(data, bucket, 'Temp/X17A5-FORMS.json')\n",
    "    \n",
    "    # ---------------------------------------------------------------------------\n",
    "    \n",
    "    # write to a JSON file for TEXT \n",
    "    with open('/home/ec2-user/SageMaker/SEC_X17A5/temp/X17A5-TEXT.json', 'w') as file: \n",
    "        json.dump(text_dictionary, file)\n",
    "        file.close()\n",
    "    \n",
    "    # save contents to AWS S3 bucket\n",
    "    with open('/home/ec2-user/SageMaker/SEC_X17A5/temp/X17A5-TEXT.json', 'rb') as data: \n",
    "        s3.upload_fileobj(data, bucket, 'Temp/X17A5-TEXT.json')\n",
    "    \n",
    "    # ---------------------------------------------------------------------------\n",
    "    \n",
    "    # write to a JSON file for FORMS \n",
    "    with open('/home/ec2-user/SageMaker/SEC_X17A5/temp/ERROR-TEXTRACT.json', 'w') as file: \n",
    "        json.dump(error_dictionary, file)\n",
    "        file.close()\n",
    "    \n",
    "    # save contents to AWS S3 bucket\n",
    "    with open('/home/ec2-user/SageMaker/SEC_X17A5/temp/ERROR-TEXTRACT.json', 'rb') as data: \n",
    "        s3.upload_fileobj(data, bucket, 'Temp/ERROR-TEXTRACT.json')\n",
    "\n",
    "    print('\\n\\nFinished performing OCR on parsed FOCUS reports.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started job with id: 1f2eacdb0ae9d0b917cd12c9b916af79dbc3c81e01a8794c1ee78bbbe65ddcc5\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: SUCCEEDED\n",
      "Resultset page recieved: 1\n",
      "Resultset page recieved: 2\n",
      "Resultset page recieved: 3\n",
      "Resultset page recieved: 4\n",
      "Resultset page recieved: 5\n",
      "\n",
      "Page number(s) for extraction in PNG are [3]\n",
      "\n",
      "Started job with id: e3c87dd0340fd9ab72ec2d583f316db63b8bfe2b82fb55125da3dee68c03a211\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: SUCCEEDED\n",
      "Resultset page recieved: 1\n",
      "\n",
      "Textract-PDF dataframe\n",
      "                                                    0             1\n",
      "0                                   Resale agreements       943,054\n",
      "1   Furniture, office equipment and leasehold impr...        26,393\n",
      "2                                        Other assets       192,764\n",
      "3                                                                  \n",
      "4                     LIABILITIES AND MEMBER'S EQUITY              \n",
      "5                                        LIABILITIES:              \n",
      "6                                   Securities loaned     $ 855,958\n",
      "7   Payable to brokers, dealers and clearing organ...     1,975,740\n",
      "8                                Payable to customers    17,495,504\n",
      "9   Securities sold, but not yet purchased-at fair...       203,874\n",
      "10                              Repurchase agreements       826,987\n",
      "11                               Payable to affiliate        82,472\n",
      "12             Accrued expenses and other liabilities       505,162\n",
      "13                                  Total liabilities    21,945,697\n",
      "14                                    MEMBER'S EQUITY     2,211,420\n",
      "15              TOTAL LIABILITIES AND MEMBER'S EQUITY  $ 24,157,117\n",
      "\n",
      "Textract-PNG dataframe\n",
      "                                                    0             1\n",
      "0                                                                  \n",
      "1   Receivable from customers, net of reserve of $...    10,369,481\n",
      "2                                                                  \n",
      "3                                                                  \n",
      "4                                                                  \n",
      "5                                        Other assets       192,764\n",
      "6                                                                  \n",
      "7                     LIABILITIES AND MEMBER'S EQUITY              \n",
      "8                                        LIABILITIES:              \n",
      "9                                   Securities loaned     $ 855,958\n",
      "10  Payable to brokers, dealers and clearing organ...     1,975,740\n",
      "11                               Payable to customers    17,495,504\n",
      "12  Securities sold, but not yet purchased-at fair...       203,874\n",
      "13                              Repurchase agreements       826,987\n",
      "14                               Payable to affiliate        82,472\n",
      "15             Accrued expenses and other liabilities       505,162\n",
      "16                                  Total liabilities    21,945,697\n",
      "17                                    MEMBER'S EQUITY     2,211,420\n",
      "18              TOTAL LIABILITIES AND MEMBER'S EQUITY  $ 24,157,117\n"
     ]
    }
   ],
   "source": [
    "# single reading for testing purposes and debugging Textract results e.g. 853784-2002-03-01, 808379-2017-03-01\n",
    "a = textractParse('Input/X-17A-5-PDF-SUBSETS/356628-2007-03-01-subset.pdf', \n",
    "              'Input/X-17A-5-PNG-SUBSETS/356628-2007-03-01/', 'ran-s3-systemic-risk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# readPNG([4], 'Input/X-17A-5-PNG-SUBSETS/318336-2018-03-01/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # temporary data frame object for balance sheet information\n",
    "# res = runJob('ran-s3-systemic-risk', 'Input/bs_test1.pdf')\n",
    "\n",
    "# # if Textract job did not fail we continue extraction\n",
    "# if res[0]['JobStatus'] != 'FAILED':\n",
    "    \n",
    "#     print(readTable(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # temporary data frame object for balance sheet information\n",
    "# res = runJob('ran-s3-systemic-risk', 'Input/X-17A-5-PDF-SUBSETS/808379-2018-03-01-subset.pdf')\n",
    "\n",
    "# # if Textract job did not fail we continue extraction\n",
    "# if res[0]['JobStatus'] != 'FAILED':\n",
    "    \n",
    "#     print(readTable(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # temporary data frame object for balance sheet information\n",
    "# res = runJob('ran-s3-systemic-risk', 'Input/X-17A-5-PDF-SUBSETS/356628-2006-03-02-subset.pdf')\n",
    "\n",
    "# # if Textract job did not fail we continue extraction\n",
    "# if res[0]['JobStatus'] != 'FAILED':\n",
    "    \n",
    "#     # format the Textract response type \n",
    "#     doc = trp.Document(res)\n",
    "    \n",
    "#     # iterate through document pages\n",
    "#     for page in doc.pages:\n",
    "        \n",
    "#         # itterate through page tables\n",
    "#         for table in page.tables: \n",
    "            \n",
    "#             # convert trp-table into dataframe object\n",
    "#             df = trp2df(table)\n",
    "#             print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# readTable(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (11046 + 2254 + 189), 13482"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
