{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sagemaker.session import Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Asset and Liability Line Items\n",
    "**We divide asset and liability line items according to a regex parse**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bsSplit(array: np.ndarray) -> tuple:\n",
    "    \"\"\"\n",
    "    Function splits an array by bisection, into asset and liability & equity terms. Assumes that line items\n",
    "    are recorded according to standard accounting practices in orientation. \n",
    "    ------------------------------------------------------------------------------------\n",
    "    :param: (type numpy.ndarray)\n",
    "        An array of balance sheet line items for a given broker-dealer\n",
    "        \n",
    "    :return: (type tuple)\n",
    "        Return a tuple of arrays; index 1 is the asset items, index 2 is the liability & equity items and\n",
    "        index 3 is the index where the split occured\n",
    "        \n",
    "    NOTE: We make the assumption that liability line items always fall below asset line items and each \n",
    "          balance sheet has both asset and liability line items. If either are missing we avoid balance sheet\n",
    "    \"\"\"\n",
    "    idx = 0\n",
    "    \n",
    "    # iterate through the line items as provided by the array\n",
    "    for i, item in enumerate(array):\n",
    "        # search string for presence of word 'assets' \n",
    "        val = re.search('assets', item, flags=re.I)\n",
    "        \n",
    "        ## Potential future update - check liability handle versus asset position \n",
    "        ## (should never have an asset index after the liability portion - JP Morgan 2012/2013 Error)\n",
    "        \n",
    "        # if we find the term \"asset\" we split the line items and break inner loop\n",
    "        if val is not None:\n",
    "            idx = i + 1    \n",
    "            \n",
    "    # partition the array by the enumerated index for asset and liability portions\n",
    "    lhs = array[:idx]\n",
    "    rhs = array[idx:]\n",
    "    \n",
    "    # if either asset or liability side missing, we return None\n",
    "    if lhs.size == 0 or rhs.size == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return (lhs, rhs, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lineItems(vector:np.ndarray, df:pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Retrieving balance sheet information line item names for s3 files\n",
    "    ------------------------------------------------------------------------------------\n",
    "    :param vector: (type numpy.ndarray)\n",
    "        An array of file names for .csv files from s3 to iterate through\n",
    "        \n",
    "    :return: (type tuple)\n",
    "        Return a tuple of arrays; left is the asset items, and right is the liability & equity items \n",
    "    \"\"\"\n",
    "    \n",
    "    # retrieve the asset and liability & equity terms from the dataframe\n",
    "    response = bsSplit(vector)\n",
    "    \n",
    "    # if response is present we continue \n",
    "    if response is not None:\n",
    "        lhs, rhs, index = response      # decompose response object to retrieve index\n",
    "        \n",
    "        print('\\tAsset Lineitems')\n",
    "        print(lhs)\n",
    "        print('\\tLiability & Equity Lineitems')\n",
    "        print(rhs)\n",
    "        \n",
    "        # save contents of asset and liability splits to AWS S3 bucket\n",
    "        dfA = df.iloc[:index]            # asset dataframe\n",
    "        dfL = df.iloc[index:]            # liability and equity dataframe\n",
    "        \n",
    "        return (dfA, dfL)\n",
    "    else:\n",
    "        return None\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Output/X-17A-5-CLEAN/1224385-2004-03-01.csv\n",
      "We've already downloaded 1224385-2004-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/1224385-2005-03-01.csv\n",
      "We've already downloaded 1224385-2005-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/1224385-2006-03-01.csv\n",
      "We've already downloaded 1224385-2006-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/1224385-2007-03-01.csv\n",
      "We've already downloaded 1224385-2007-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/1224385-2008-02-29.csv\n",
      "We've already downloaded 1224385-2008-02-29.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/1224385-2009-03-02.csv\n",
      "We've already downloaded 1224385-2009-03-02.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/1224385-2010-03-12.csv\n",
      "We've already downloaded 1224385-2010-03-12.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/1224385-2011-03-01.csv\n",
      "We've already downloaded 1224385-2011-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/1224385-2012-02-29.csv\n",
      "We've already downloaded 1224385-2012-02-29.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/1224385-2013-03-01.csv\n",
      "We've already downloaded 1224385-2013-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/1224385-2014-03-04.csv\n",
      "We've already downloaded 1224385-2014-03-04.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/1224385-2015-03-02.csv\n",
      "We've already downloaded 1224385-2015-03-02.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/1224385-2016-02-29.csv\n",
      "We've already downloaded 1224385-2016-02-29.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/1224385-2017-03-01.csv\n",
      "We've already downloaded 1224385-2017-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/1224385-2018-02-28.csv\n",
      "We've already downloaded 1224385-2018-02-28.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/1224385-2019-02-28.csv\n",
      "We've already downloaded 1224385-2019-02-28.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/1224385-2020-02-28.csv\n",
      "We've already downloaded 1224385-2020-02-28.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/1224385-2021-02-26.csv\n",
      "We've already downloaded 1224385-2021-02-26.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/42352-2002-01-30.csv\n",
      "We've already downloaded 42352-2002-01-30.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/42352-2003-01-28.csv\n",
      "We've already downloaded 42352-2003-01-28.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/42352-2004-01-27.csv\n",
      "We've already downloaded 42352-2004-01-27.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/42352-2005-01-25.csv\n",
      "We've already downloaded 42352-2005-01-25.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/42352-2006-01-24.csv\n",
      "We've already downloaded 42352-2006-01-24.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/42352-2007-01-23.csv\n",
      "We've already downloaded 42352-2007-01-23.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/42352-2008-01-29.csv\n",
      "We've already downloaded 42352-2008-01-29.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/42352-2010-03-01.csv\n",
      "We've already downloaded 42352-2010-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/42352-2011-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/42352-2013-03-01.csv\n",
      "We've already downloaded 42352-2013-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/42352-2014-07-31.csv\n",
      "We've already downloaded 42352-2014-07-31.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/42352-2015-03-10.csv\n",
      "We've already downloaded 42352-2015-03-10.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/42352-2016-02-23.csv\n",
      "We've already downloaded 42352-2016-02-23.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/42352-2017-03-01.csv\n",
      "We've already downloaded 42352-2017-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/42352-2018-02-27.csv\n",
      "We've already downloaded 42352-2018-02-27.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/42352-2019-03-01.csv\n",
      "We've already downloaded 42352-2019-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/42352-2021-02-25.csv\n",
      "We've already downloaded 42352-2021-02-25.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/58056-2002-03-01.csv\n",
      "We've already downloaded 58056-2002-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/58056-2003-03-03.csv\n",
      "We've already downloaded 58056-2003-03-03.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/58056-2004-02-27.csv\n",
      "We've already downloaded 58056-2004-02-27.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/58056-2004-03-26.csv\n",
      "We've already downloaded 58056-2004-03-26.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/58056-2005-02-25.csv\n",
      "We've already downloaded 58056-2005-02-25.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/58056-2006-03-24.csv\n",
      "We've already downloaded 58056-2006-03-24.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/58056-2007-03-01.csv\n",
      "We've already downloaded 58056-2007-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/58056-2008-02-29.csv\n",
      "We've already downloaded 58056-2008-02-29.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/58056-2009-03-16.csv\n",
      "We've already downloaded 58056-2009-03-16.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/58056-2012-02-29.csv\n",
      "We've already downloaded 58056-2012-02-29.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/58056-2013-03-01.csv\n",
      "We've already downloaded 58056-2013-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/58056-2014-03-04.csv\n",
      "We've already downloaded 58056-2014-03-04.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/58056-2015-03-02.csv\n",
      "We've already downloaded 58056-2015-03-02.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/58056-2016-02-29.csv\n",
      "We've already downloaded 58056-2016-02-29.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/58056-2017-03-03.csv\n",
      "We've already downloaded 58056-2017-03-03.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/58056-2018-03-12.csv\n",
      "We've already downloaded 58056-2018-03-12.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/58056-2019-03-01.csv\n",
      "We've already downloaded 58056-2019-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/58056-2019-09-30.csv\n",
      "We've already downloaded 58056-2019-09-30.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/58056-2020-03-02.csv\n",
      "We've already downloaded 58056-2020-03-02.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/58056-2021-03-01.csv\n",
      "We've already downloaded 58056-2021-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/68136-2002-01-29.csv\n",
      "We've already downloaded 68136-2002-01-29.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/68136-2003-01-30.csv\n",
      "We've already downloaded 68136-2003-01-30.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/68136-2004-01-30.csv\n",
      "We've already downloaded 68136-2004-01-30.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/68136-2005-01-31.csv\n",
      "We've already downloaded 68136-2005-01-31.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/68136-2006-01-30.csv\n",
      "We've already downloaded 68136-2006-01-30.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/68136-2007-01-29.csv\n",
      "We've already downloaded 68136-2007-01-29.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/68136-2008-01-31.csv\n",
      "We've already downloaded 68136-2008-01-31.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/68136-2009-01-29.csv\n",
      "We've already downloaded 68136-2009-01-29.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/68136-2010-03-02.csv\n",
      "We've already downloaded 68136-2010-03-02.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/68136-2011-03-02.csv\n",
      "We've already downloaded 68136-2011-03-02.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/68136-2012-02-29.csv\n",
      "We've already downloaded 68136-2012-02-29.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/68136-2013-03-01.csv\n",
      "We've already downloaded 68136-2013-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/68136-2014-03-04.csv\n",
      "We've already downloaded 68136-2014-03-04.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/68136-2015-03-02.csv\n",
      "We've already downloaded 68136-2015-03-02.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/68136-2016-02-29.csv\n",
      "We've already downloaded 68136-2016-02-29.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/68136-2017-03-01.csv\n",
      "We've already downloaded 68136-2017-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/68136-2018-03-01.csv\n",
      "We've already downloaded 68136-2018-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/68136-2019-03-01.csv\n",
      "We've already downloaded 68136-2019-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/68136-2021-02-26.csv\n",
      "We've already downloaded 68136-2021-02-26.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/72267-2003-05-30.csv\n",
      "We've already downloaded 72267-2003-05-30.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/72267-2004-05-28.csv\n",
      "We've already downloaded 72267-2004-05-28.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/72267-2005-05-31.csv\n",
      "We've already downloaded 72267-2005-05-31.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/72267-2006-05-30.csv\n",
      "We've already downloaded 72267-2006-05-30.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/72267-2007-05-29.csv\n",
      "We've already downloaded 72267-2007-05-29.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/72267-2008-05-30.csv\n",
      "We've already downloaded 72267-2008-05-30.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/72267-2009-06-03.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/72267-2010-06-01.csv\n",
      "We've already downloaded 72267-2010-06-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/72267-2012-03-15.csv\n",
      "We've already downloaded 72267-2012-03-15.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/72267-2012-05-30.csv\n",
      "We've already downloaded 72267-2012-05-30.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/72267-2013-05-30.csv\n",
      "We've already downloaded 72267-2013-05-30.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/72267-2014-05-30.csv\n",
      "We've already downloaded 72267-2014-05-30.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/72267-2015-06-01.csv\n",
      "We've already downloaded 72267-2015-06-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/72267-2016-05-31.csv\n",
      "We've already downloaded 72267-2016-05-31.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/72267-2017-05-30.csv\n",
      "We've already downloaded 72267-2017-05-30.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/72267-2018-05-25.csv\n",
      "We've already downloaded 72267-2018-05-25.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/72267-2019-05-28.csv\n",
      "We've already downloaded 72267-2019-05-28.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/72267-2020-06-01.csv\n",
      "We've already downloaded 72267-2020-06-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/782124-2002-01-29.csv\n",
      "We've already downloaded 782124-2002-01-29.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/782124-2003-01-30.csv\n",
      "We've already downloaded 782124-2003-01-30.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/782124-2004-01-30.csv\n",
      "We've already downloaded 782124-2004-01-30.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/782124-2004-05-07.csv\n",
      "We've already downloaded 782124-2004-05-07.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/782124-2005-01-31.csv\n",
      "We've already downloaded 782124-2005-01-31.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/782124-2006-01-30.csv\n",
      "We've already downloaded 782124-2006-01-30.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/782124-2007-01-29.csv\n",
      "We've already downloaded 782124-2007-01-29.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/782124-2008-01-31.csv\n",
      "We've already downloaded 782124-2008-01-31.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/782124-2009-03-02.csv\n",
      "We've already downloaded 782124-2009-03-02.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/782124-2010-03-01.csv\n",
      "We've already downloaded 782124-2010-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/782124-2011-03-02.csv\n",
      "We've already downloaded 782124-2011-03-02.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/782124-2012-02-29.csv\n",
      "We've already downloaded 782124-2012-02-29.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/782124-2013-03-01.csv\n",
      "We've already downloaded 782124-2013-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/782124-2014-03-05.csv\n",
      "We've already downloaded 782124-2014-03-05.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/782124-2015-02-27.csv\n",
      "We've already downloaded 782124-2015-02-27.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/782124-2016-02-29.csv\n",
      "We've already downloaded 782124-2016-02-29.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/782124-2017-03-01.csv\n",
      "We've already downloaded 782124-2017-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/782124-2018-02-27.csv\n",
      "We've already downloaded 782124-2018-02-27.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/782124-2018-02-28.csv\n",
      "We've already downloaded 782124-2018-02-28.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/782124-2019-02-28.csv\n",
      "We've already downloaded 782124-2019-02-28.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/782124-2020-04-01.csv\n",
      "We've already downloaded 782124-2020-04-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/782124-2021-03-01.csv\n",
      "We've already downloaded 782124-2021-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/851376-2002-03-01.csv\n",
      "We've already downloaded 851376-2002-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/851376-2003-03-03.csv\n",
      "We've already downloaded 851376-2003-03-03.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/851376-2004-03-01.csv\n",
      "We've already downloaded 851376-2004-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/851376-2005-03-02.csv\n",
      "We've already downloaded 851376-2005-03-02.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/851376-2006-03-01.csv\n",
      "We've already downloaded 851376-2006-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/851376-2008-02-29.csv\n",
      "We've already downloaded 851376-2008-02-29.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/851376-2009-03-02.csv\n",
      "We've already downloaded 851376-2009-03-02.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/851376-2010-03-01.csv\n",
      "We've already downloaded 851376-2010-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/851376-2011-03-15.csv\n",
      "We've already downloaded 851376-2011-03-15.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/851376-2012-02-29.csv\n",
      "We've already downloaded 851376-2012-02-29.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/851376-2013-03-01.csv\n",
      "We've already downloaded 851376-2013-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/851376-2014-03-04.csv\n",
      "We've already downloaded 851376-2014-03-04.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/851376-2016-02-29.csv\n",
      "We've already downloaded 851376-2016-02-29.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/851376-2017-03-01.csv\n",
      "We've already downloaded 851376-2017-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/851376-2018-02-28.csv\n",
      "We've already downloaded 851376-2018-02-28.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/851376-2019-03-01.csv\n",
      "We've already downloaded 851376-2019-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/851376-2020-03-06.csv\n",
      "We've already downloaded 851376-2020-03-06.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/851376-2021-03-01.csv\n",
      "We've already downloaded 851376-2021-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/853784-2002-03-01.csv\n",
      "We've already downloaded 853784-2002-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/853784-2003-02-28.csv\n",
      "We've already downloaded 853784-2003-02-28.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/853784-2004-03-01.csv\n",
      "We've already downloaded 853784-2004-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/853784-2005-02-28.csv\n",
      "We've already downloaded 853784-2005-02-28.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/853784-2006-03-01.csv\n",
      "We've already downloaded 853784-2006-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/853784-2007-03-01.csv\n",
      "We've already downloaded 853784-2007-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/853784-2007-03-09.csv\n",
      "We've already downloaded 853784-2007-03-09.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/853784-2008-02-29.csv\n",
      "We've already downloaded 853784-2008-02-29.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/853784-2009-03-02.csv\n",
      "We've already downloaded 853784-2009-03-02.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/853784-2010-03-01.csv\n",
      "We've already downloaded 853784-2010-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/853784-2011-03-01.csv\n",
      "We've already downloaded 853784-2011-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/853784-2012-02-29.csv\n",
      "We've already downloaded 853784-2012-02-29.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/853784-2013-03-01.csv\n",
      "We've already downloaded 853784-2013-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/853784-2014-03-04.csv\n",
      "We've already downloaded 853784-2014-03-04.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/853784-2015-03-09.csv\n",
      "We've already downloaded 853784-2015-03-09.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/853784-2016-03-01.csv\n",
      "We've already downloaded 853784-2016-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/853784-2017-03-01.csv\n",
      "We've already downloaded 853784-2017-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/853784-2018-03-05.csv\n",
      "We've already downloaded 853784-2018-03-05.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/853784-2019-03-01.csv\n",
      "We've already downloaded 853784-2019-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/853784-2020-03-02.csv\n",
      "We've already downloaded 853784-2020-03-02.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/853784-2021-03-01.csv\n",
      "We've already downloaded 853784-2021-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/91154-2002-03-01.csv\n",
      "We've already downloaded 91154-2002-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/91154-2004-02-27.csv\n",
      "We've already downloaded 91154-2004-02-27.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/91154-2005-03-01.csv\n",
      "We've already downloaded 91154-2005-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/91154-2007-03-01.csv\n",
      "We've already downloaded 91154-2007-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/91154-2008-02-29.csv\n",
      "We've already downloaded 91154-2008-02-29.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/91154-2009-03-02.csv\n",
      "We've already downloaded 91154-2009-03-02.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/91154-2010-03-02.csv\n",
      "We've already downloaded 91154-2010-03-02.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/91154-2011-03-01.csv\n",
      "We've already downloaded 91154-2011-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/91154-2012-02-29.csv\n",
      "We've already downloaded 91154-2012-02-29.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/91154-2013-03-01.csv\n",
      "We've already downloaded 91154-2013-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/91154-2014-03-04.csv\n",
      "We've already downloaded 91154-2014-03-04.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/91154-2016-03-01.csv\n",
      "We've already downloaded 91154-2016-03-01.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/91154-2017-03-02.csv\n",
      "We've already downloaded 91154-2017-03-02.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/91154-2018-03-05.csv\n",
      "We've already downloaded 91154-2018-03-05.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/91154-2019-03-05.csv\n",
      "We've already downloaded 91154-2019-03-05.csv\n",
      "\n",
      " Output/X-17A-5-CLEAN/91154-2020-03-02.csv\n",
      "We've already downloaded 91154-2020-03-02.csv\n",
      "\n",
      "All X-17A-5 files have been downloaded and split between Asset and Liability & Equity terms\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # initiate s3 bucket and corresponding data folder\n",
    "    bucket = \"ran-s3-systemic-risk\"\n",
    "    data_folder =\"Output/X-17A-5-CLEAN/\"\n",
    "    output_folder = 'Output/X-17A-5-SPLIT/'\n",
    "    temp_folder = 'Temp/'\n",
    "        \n",
    "    # Amazon Textract client and Sagemaker session\n",
    "    s3 = boto3.client('s3')\n",
    "    session = Session()\n",
    "    \n",
    "    # temp directory where JSON files is stored\n",
    "    temp = np.array(session.list_s3_files(bucket, temp_folder))\n",
    "    \n",
    "    # discover all of the pdfs that you want to parse\n",
    "    paths = np.array(session.list_s3_files(bucket, data_folder))[1:]\n",
    "    asset_split = np.array(session.list_s3_files(bucket, output_folder + 'Assets/'))\n",
    "    liability_split = np.array(session.list_s3_files(bucket, output_folder + 'Liability & Equity/'))\n",
    "   \n",
    "    # iterate through files from s3 bucket \n",
    "    for file in paths:\n",
    "        print('\\n', file)\n",
    "        fileName = file.split('/')[-1]                                      # file-name for a given path\n",
    "        asset_name = output_folder + 'Assets/' + fileName                   # export path to assets\n",
    "        liability_name = output_folder + 'Liability & Equity/' + fileName   # export path to liability and equity\n",
    "        \n",
    "        # check to see presence of split files \n",
    "        if (asset_name not in asset_split) or (liability_name not in liability_split):\n",
    "        \n",
    "            # download temporary file from s3 bucket\n",
    "            s3.download_file(bucket, file, 'temp.csv')\n",
    "            df = pd.read_csv('temp.csv')\n",
    "\n",
    "            n = df.columns.size   # the number of columns in read dataframe    \n",
    "\n",
    "            if n > 1: # if there is more than 1 column we continue examination \n",
    "\n",
    "                # all line item for balance sheet (first column)\n",
    "                arr = df[df.columns[0]].dropna().values     \n",
    "\n",
    "                # extract line items if possible for both asset and liability terms\n",
    "                response = lineItems(arr, df)\n",
    "\n",
    "                # if response not None we decompose each\n",
    "                if response is not None:\n",
    "                    # unpack the response object to component parts\n",
    "                    df_asset, df_liability = response\n",
    "\n",
    "                    # writing data frame to .csv file (we overwrite file name to save space)\n",
    "                    df_asset.to_csv(fileName, index=False)\n",
    "                    with open(fileName, 'rb') as data:\n",
    "                        s3.put_object(Bucket=bucket, Key=asset_name, Body=data)\n",
    "\n",
    "                    df_liability.to_csv(fileName, index=False)\n",
    "                    with open(fileName, 'rb') as data:\n",
    "                        s3.put_object(Bucket=bucket, Key=liability_name, Body=data)\n",
    "\n",
    "                    # remove local file after it has been created\n",
    "                    os.remove(fileName)\n",
    "\n",
    "            else:\n",
    "                print('{} incomplete dataframe'.format(file))\n",
    "                \n",
    "        else:\n",
    "            print(\"We've already downloaded {}\".format(fileName))\n",
    "        \n",
    "    # remove local file for storing cleaned data  \n",
    "    os.remove('temp.csv')\n",
    "    print('\\nAll X-17A-5 files have been downloaded and split between Asset and Liability & Equity terms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
